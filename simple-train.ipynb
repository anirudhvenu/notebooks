{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import time\n",
    "import pdb\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#             print(ansIdx.size())\n",
    "#             b_no = 0\n",
    "#             ans_list = []\n",
    "            \n",
    "#             for elem in ansIdx:\n",
    "#                 t = ((optIdx[b_no,:]==elem).nonzero())\n",
    "#             #     print(t.size())\n",
    "#                 if (t.size()!=torch.Size([])):\n",
    "#                     ans_list.append(t[0][0])\n",
    "#                 else:\n",
    "#                     ans_list.append((-1))\n",
    "    \n",
    "#                 b_no = b_no + 1\n",
    "\n",
    "#             corr_ans_ind = torch.LongTensor(ans_list)\n",
    "            \n",
    "\n",
    "#             corr_ans_ind = Variable(corr_ans_ind)\n",
    "#             corr_ans_ind = corr_ans_ind.cuda()\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Seed: ', 1377)\n"
     ]
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000) # fix seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enCuda = 1\n",
    "if enCuda:\n",
    "    torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netE(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, dropout, img_feat_size):\n",
    "        super(_netE, self).__init__()\n",
    "\n",
    "        self.d = dropout\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.nhid = nhid\n",
    "        self.ninp = ninp\n",
    "        self.img_feat_size = img_feat_size\n",
    "\n",
    "        self.img_embed = nn.Linear(img_feat_size, nhid)\n",
    "        self.ques_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "        self.his_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "\n",
    "        self.Wq_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wh_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wi_1 = nn.Linear(self.img_feat_size, self.nhid)\n",
    "        self.Wa_1 = nn.Linear(self.nhid, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.nhid*3, self.ninp)\n",
    "\n",
    "    def forward(self, ques_emb, his_emb, img_raw, ques_hidden, his_hidden, rnd):\n",
    "\n",
    "        img_emb = F.tanh(self.img_embed(img_raw))\n",
    "        ques_feat, ques_hidden = self.ques_rnn(ques_emb, ques_hidden)\n",
    "        ques_feat = ques_feat[-1]\n",
    "        his_feat, his_hidden = self.his_rnn(his_emb, his_hidden)\n",
    "        his_feat = his_feat[-1]\n",
    "\n",
    "        ques_emb_1 = self.Wq_1(ques_feat).view(-1, 1, self.nhid)\n",
    "        his_emb_1 = self.Wh_1(his_feat).view(-1, rnd, self.nhid)\n",
    "        his_cat = his_emb_1.mean(1)\n",
    "\n",
    "        img_cat = img_emb.view(-1,49,self.nhid)\n",
    "        img_cat = img_cat.mean(1)\n",
    "        \n",
    "        concat_feat = torch.cat((ques_feat, his_cat.view(-1, self.nhid), \\\n",
    "                                 img_cat.view(-1, self.nhid)),1)\n",
    "        \n",
    "        encoder_feat = F.tanh(self.fc1(F.dropout(concat_feat, self.d, training=self.training)))\n",
    "\n",
    "        return encoder_feat, ques_hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####CHANGE CUDA\n",
    "\n",
    "class _netW(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, dropout):\n",
    "        super(_netW, self).__init__()\n",
    "        self.word_embed = nn.Embedding(ntoken+1, ninp)\n",
    "        self.Linear = share_Linear(self.word_embed.weight)\n",
    "        \n",
    "        if enCuda:\n",
    "            self.word_embed = nn.Embedding(ntoken+1, ninp).cuda()\n",
    "            self.Linear = share_Linear(self.word_embed.weight).cuda()\n",
    "\n",
    "        self.init_weights()\n",
    "        self.d = dropout\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.word_embed.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, format ='index'):\n",
    "        if format == 'onehot':\n",
    "            out = F.dropout(self.Linear(input), self.d, training=self.training)\n",
    "        elif format == 'index':\n",
    "            out = F.dropout(self.word_embed(input), self.d, training=self.training)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    \"\"\"\n",
    "    Given the real/wrong/fake answer, use a RNN (LSTM) to embed the answer.\n",
    "    \"\"\"\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, ntoken, dropout):\n",
    "        super(_netD, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.ntoken = ntoken\n",
    "        self.ninp = ninp\n",
    "        self.d = dropout\n",
    "\n",
    "        self.ans_rnn = nn.LSTM(self.ninp, self.ninp, self.nlayers)\n",
    "        self.W2 = nn.Linear(self.nhid, 1)\n",
    "        self.fc = nn.Linear(nhid, ninp)\n",
    "\n",
    "    def forward(self, input_feat, hidden, opt_ans_emb, vocab_size):\n",
    "\n",
    "        # opt_ans_emb = self.ans_emb(opt_ans.view(-1,200,9))\n",
    "#         print(type(hidden[0]))\n",
    "        output, h = self.ans_rnn(opt_ans_emb, hidden)\n",
    "        output = output[-1]\n",
    "#         output = output.view(100,-1,self.ninp)        \n",
    "        # redOutput = output.mean(1).view(100,self.ninp,-1)\n",
    "        output_feat = output.view(-1,100,self.ninp)\n",
    "        expand_feat = input_feat.view(-1,self.ninp,1)\n",
    "\n",
    "#         print('-------------Within Decoder:')\n",
    "\n",
    "\n",
    "#         print('expand_feat',expand_feat)\n",
    "#         feat = output_feat.view(-1,100,1,self.ninp)\n",
    "#         expand_feat = expand_feat.expand(feat.size())\n",
    "#         expand_feat = expand_feat.view(-1,1,self.ninp)\n",
    "#         print(output_feat)\n",
    "#         print('output_feat:',output_feat.mean())\n",
    "#         print('expand feat:', expand_feat.mean())\n",
    "#         print('matmul:',torch.bmm(output_feat,expand_feat))\n",
    "        prob = F.log_softmax(torch.bmm(output_feat,expand_feat).t())\n",
    "#         print(torch.bmm(output_feat,expand_feat))\n",
    "        prob = prob.view(-1,100)\n",
    "        return prob\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.ninp).zero_())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h, batch_size):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data.resize_(h.size(0), batch_size, h.size(2)).zero_())\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v, batch_size) for v in h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class train(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "            \n",
    "        self.img_info = self.img_info[s:e]\n",
    "\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # get the image\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ques_ori = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, self.negative_sample, self.ans_length+1))\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, self.negative_sample))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        ans_idx = np.zeros((self.rnd))\n",
    "        opt_ans_idx = np.zeros((self.rnd, self.negative_sample))\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                his[i+1, self.his_length-qa_len:self.his_length-a_len] = self.ques[index, i, :q_len]\n",
    "                his[i+1, self.his_length-a_len:] = self.ans[index, i, :a_len]\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "\n",
    "            ques_ori[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            # random select the negative samples.\n",
    "            ans_idx[i] = opt_ids[self.ans_ids[index, i]]\n",
    "            # exclude the gt index.\n",
    "            opt_ids = np.delete(opt_ids, ans_idx[i], 0)\n",
    "            random.shuffle(opt_ids)\n",
    "            for j in range(self.negative_sample):\n",
    "                ids = opt_ids[j]\n",
    "                opt_ans_idx[i,j] = ids\n",
    "\n",
    "                opt_len = self.opt_len[ids]\n",
    "                \n",
    "                opt_ans_len[i, j] = opt_len\n",
    "                \n",
    "                opt_ans[i, j, 1:opt_len+1] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, 0] = self.vocab_size\n",
    "                \n",
    "#                 opt_ans[i, j, :opt_len] = self.opt_list[ids,:opt_len]\n",
    "#                 opt_ans[i, j, opt_len] = self.vocab_size\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        ques_ori = torch.from_numpy(ques_ori)\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        ans_idx = torch.from_numpy(ans_idx)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "        opt_ans_idx = torch.from_numpy(opt_ans_idx)\n",
    "        return img, his, ques, ans, ans_target, ans_len, ans_idx, ans_ids, ques_ori, \\\n",
    "                opt_ans, opt_ans_len, opt_ans_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class validate(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "\n",
    "        self.img_info = self.img_info[s:e]\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "###########################################################################################\n",
    "#CHANGE THIS HERE FOR NON DEMO TRAINING SET\n",
    "#         split = 'train'\n",
    "###########################################################################################\n",
    "        \n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # get the image\n",
    "        img_id = self.img_info[index]['imgId']\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        quesL = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        opt_ans_target = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, 100))\n",
    "\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                ques_ans = np.concatenate([self.ques[index, i, :q_len], self.ans[index, i, :a_len]])\n",
    "                his[i+1, self.his_length-qa_len:] = ques_ans\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "            quesL[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_idx = self.ans_ids[index, i]\n",
    "\n",
    "            for j, ids in enumerate(opt_ids):\n",
    "                opt_len = self.opt_len[ids]\n",
    "                opt_ans[i, j, 1:opt_len+1] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, 0] = self.vocab_size\n",
    "\n",
    "                opt_ans_target[i, j,:opt_len] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans_target[i, j,opt_len] = self.vocab_size\n",
    "                opt_ans_len[i, j] = opt_len\n",
    "\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        opt_ans_target = torch.from_numpy(opt_ans_target)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        quesL = torch.from_numpy(quesL)\n",
    "\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "\n",
    "        return img, his, ques, ans, ans_target, quesL, opt_ans, \\\n",
    "                    opt_ans_target, ans_ids, ans_len, opt_ans_len, img_id\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(epoch):\n",
    "    netW.train()\n",
    "    netE.train()\n",
    "    netD.train()\n",
    "\n",
    "#     lr = adjust_learning_rate(optimizer, epoch, opt.lr)\n",
    "\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "\n",
    "    data_iter = iter(dloader)\n",
    "\n",
    "    average_loss = 0\n",
    "    count = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(dloader):\n",
    "\n",
    "        t1 = time.time()\n",
    "        data = data_iter.next()\n",
    "        \n",
    "        image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answerIds, answerLen, opt_answerLen, img_id  = data\n",
    "            \n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "#         print(image.size(),'image size')\n",
    "#         print(img_input.size(),'img_input')\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            netW.zero_grad()\n",
    "            netE.zero_grad()\n",
    "            netD.zero_grad()\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            ans = answer[:,rnd,:].t()\n",
    "            tans = answerT[:,rnd,:].t()\n",
    "#             wrong_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "\n",
    "#             real_len = answerLen[:,rnd]\n",
    "#             wrong_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            ans_input.data.resize_(ans.size()).copy_(ans)\n",
    "            ans_target.data.resize_(tans.size()).copy_(tans)\n",
    "#             wrong_ans_input.data.resize_(wrong_ans.size()).copy_(wrong_ans)\n",
    "\n",
    "            # sample in-batch negative index\n",
    "#             batch_sample_idx.data.resize_(batch_size, neg_batch_sample).zero_()\n",
    "#             sample_batch_neg(answerIdx[:,rnd], opt_answerIdx[:,rnd,:], batch_sample_idx, neg_batch_sample)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "            \n",
    "#             print('----------------Encoder:')\n",
    "#             print('ques_emb',ques_emb.size())\n",
    "#             print('his_emb',his_emb.size())\n",
    "#             print('img input size:', img_input.size())\n",
    "            \n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "#             ans_real_emb = netW(ans_target, format='index')\n",
    "#             ans_wrong_emb = netW(wrong_ans_input, format='index')\n",
    "\n",
    "#             real_hidden = repackage_hidden(real_hidden, batch_size)\n",
    "#             wrong_hidden = repackage_hidden(wrong_hidden, ans_wrong_emb.size(1))\n",
    "\n",
    "#             real_feat = netD(ans_real_emb, ans_target, real_hidden, vocab_size)\n",
    "#             wrong_feat = netD(ans_wrong_emb, wrong_ans_input, wrong_hidden, vocab_size)\n",
    "\n",
    "#             batch_wrong_feat = wrong_feat.index_select(0, batch_sample_idx.view(-1))\n",
    "#             wrong_feat = wrong_feat.view(batch_size, -1, ninp)\n",
    "#             batch_wrong_feat = batch_wrong_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "#             nPairLoss = critD(featD, real_feat, wrong_feat, batch_wrong_feat)\n",
    "\n",
    "#             opt_ans = opt_answerT[:,:,rnd,:].clone().view(-1, ans_length).t()\n",
    "#             opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "            \n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "\n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "\n",
    "            opt_hidden = netD.init_hidden(batchSize)\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "#             print('--------------Decoder:')\n",
    "#             print('opt_ans_input',opt_ans_input.size())\n",
    "#             print('featD', featD[0])\n",
    "#             print('opt_ans_emb',opt_ans_emb.size())\n",
    "            \n",
    "            prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "#             optIdx = opt_answerIdx[:,rnd,:]\n",
    "            # print(optIdx.size())\n",
    "            ansIds = answerIds[:,rnd]\n",
    "            ansIds = ansIds.long()\n",
    "            ansIds = Variable(ansIds, requires_grad = False)\n",
    "            \n",
    "            if enCuda:\n",
    "                ansIds = ansIds.cuda()\n",
    "            \n",
    "\n",
    "#             print(ansIds)            \n",
    "            currLoss = critD(prob,ansIds)\n",
    "#             print('currLoss:',currLoss[0])\n",
    "            average_loss += currLoss.data[0]\n",
    "#             print(currLoss.size())\n",
    "#             print(currLoss[0])\n",
    "            currLoss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "\n",
    "        i += 1\n",
    "        if i % log_interval == 0:\n",
    "            average_loss /= count\n",
    "            print(\"step {} / {} (epoch {}), average loss {:.3f}, lr = {:.6f}\"\\\n",
    "                .format(i, len(dloader), epoch, average_loss, lr))\n",
    "            average_loss = 0\n",
    "            count = 0\n",
    "\n",
    "    return average_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valModel():\n",
    "    netE.eval()\n",
    "    netW.eval()\n",
    "    netD.eval()\n",
    "\n",
    "#     n_neg = 100\n",
    "    data_iter_val = iter(dataloader_val)\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "    i = 0\n",
    "\n",
    "    average_loss = 0\n",
    "    rank_all_tmp = []\n",
    "\n",
    "#     while i < len(dataloader_val):\n",
    "    while i < 10:\n",
    "        data = data_iter_val.next()\n",
    "        image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answer_ids, answerLen, opt_answerLen, img_id  = data\n",
    "\n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "        #image = l2_norm(image)\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            gt_id = answer_ids[:,rnd]\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "            gt_index.data.resize_(gt_id.size()).copy_(gt_id)\n",
    "            opt_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "            \n",
    "#             print('----------------Encoder:')\n",
    "#             print('ques_emb',ques_emb.size())\n",
    "#             print('his_emb',his_emb.size())\n",
    "#             print('img input size:', img_input.size())\n",
    "            \n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "\n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "#             print('featD',featD)\n",
    "#             print('opt_ans_emb',opt_ans_emb)            \n",
    "#             print('--------------Decoder:')\n",
    "#             print('opt_ans_input',opt_ans_input.size())\n",
    "#             print('featD', featD.size())\n",
    "#             print('opt_ans_emb',opt_ans_emb.size())\n",
    "            \n",
    "            score = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "#             print('score:',score)\n",
    "#             opt_feat = opt_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "            #ans_emb = ans_emb.view(ans_length, -1, 100, opt.nhid)\n",
    "#             featD = featD.view(-1, ninp, 1)\n",
    "#             score = torch.bmm(opt_feat, featD)\n",
    "#             score = score.view(-1, 100)\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                gt_index.data[b] = gt_index.data[b] + b*100\n",
    "\n",
    "            gt_score = score.view(-1).index_select(0, gt_index)\n",
    "            sort_score, sort_idx = torch.sort(score, 1, descending=True)\n",
    "#             print('sort_score[0]:',sort_score[0].data)\n",
    "            count = sort_score.gt(gt_score.view(-1,1).expand_as(sort_score))\n",
    "            rank = count.sum(1) + 1\n",
    "            rank_all_tmp += list(rank.view(-1).data.cpu().numpy())\n",
    "            \n",
    "        i += 1\n",
    "        sys.stdout.write('Evaluating: {:d}/{:d}  \\r' \\\n",
    "          .format(i, len(dataloader_val)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return rank_all_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class share_Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = Ax + b`\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias. Default: True\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in\\_features)`\n",
    "        - Output: :math:`(N, out\\_features)`\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape (out_features x in_features)\n",
    "        bias:   the learnable bias of the module of shape (out_features)\n",
    "    Examples::\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = autograd.Variable(torch.randn(128, 20))\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight):\n",
    "        super(share_Linear, self).__init__()\n",
    "        self.in_features = weight.size(0)\n",
    "        self.out_features = weight.size(1)\n",
    "        self.weight = weight.t()\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + str(self.in_features) + ' -> ' \\\n",
    "            + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip_gradient(model):\n",
    "    \"\"\"Computes a gradient clipping coefficient based on gradient norm.\"\"\"\n",
    "    totalnorm = 0\n",
    "    for p in model.parameters():\n",
    "        p.grad.data.clamp_(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'LSTM'\n",
    "ninp = 300\n",
    "nhid = 512\n",
    "nlayers = 1\n",
    "dropout = 0.5\n",
    "margin = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Here for input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_img_h5 = 'vdl_img_vgg_demo.h5'\n",
    "# input_ques_h5 = 'visdial_data_demo.h5'\n",
    "input_img_h5 = 'vdl_img_vgg.h5'\n",
    "input_ques_h5 = 'visdial_data.h5'\n",
    "input_json = 'visdial_params.json'\n",
    "negative_sample = 20\n",
    "num_val = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: train\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "train number of data: 81783\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "dataset = train(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: test\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "test number of data: 40504\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "dataset_val = validate(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "num_workers = 0\n",
    "dloader = torch.utils.data.DataLoader(dataset_val, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=int(num_workers))\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=1,\n",
    "                                         shuffle=False, num_workers=int(num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_iter1 = iter(dloader)\n",
    "data = data_iter1.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in case dataloader used is dloader\n",
    "# image, history, question, answer, answerT, answerLen, answerIdx, answerIds, questionL, \\\n",
    "#         opt_answerT, opt_answerLen, opt_answerIdx = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wantVal = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if wantVal == 0:\n",
    "    image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answerIds, answerLen, opt_answerLen, img_id  = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if wantVal == 1:\n",
    "    data_iter_val = iter(dataloader_val)\n",
    "    data_val = data_iter_val.next()\n",
    "    image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answer_ids, answerLen, opt_answerLen, img_id  = data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd = 3\n",
    "ques_length = dataset.ques_length\n",
    "negative_sample = 20\n",
    "n_neg = negative_sample\n",
    "vocab_size = dataset.vocab_size\n",
    "ques_length = dataset.ques_length\n",
    "ans_length = dataset.ans_length + 1\n",
    "his_length = dataset.ans_length + dataset.ques_length\n",
    "itow = dataset.itow\n",
    "img_feat_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netW = _netW(vocab_size, ninp, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netE = _netE(model, ninp, nhid, nlayers, dropout, img_feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    netE.cuda()\n",
    "    netW.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "if enCuda:\n",
    "    ques_input = ques_input.cuda()\n",
    "ques_input = Variable(ques_input)\n",
    "ques = question[:,rnd,:].t()\n",
    "ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "\n",
    "ques_emb = netW(ques_input, format = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = image.view(-1, img_feat_size)\n",
    "img_input = torch.FloatTensor(batchSize)\n",
    "img_input = Variable(img_input)\n",
    "img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "if(enCuda):\n",
    "    his_input = his_input.cuda()\n",
    "his_input = Variable(his_input)\n",
    "his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "batch_size = question.size(0)\n",
    "\n",
    "ques_hidden = netE.init_hidden(batchSize)\n",
    "hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    his_input = his_input.cuda()\n",
    "    ques_input = ques_input.cuda()\n",
    "    img_input = img_input.cuda()\n",
    "    ques_emb = ques_emb.cuda()\n",
    "    his_emb = his_emb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featD, ques_hidden = netE(ques_emb, his_emb, img_input, ques_hidden, hist_hidden, rnd+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-03 *\n",
       " -5.6889\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featD.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "netD = _netD(model, ninp, nhid, nlayers, vocab_size, dropout)\n",
    "if enCuda:\n",
    "    netD.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "if enCuda:\n",
    "    opt_ans_input = opt_ans_input.cuda()\n",
    "\n",
    "opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "\n",
    "\n",
    "opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "# opt_ans_emb = opt_ans_emb.cuda()\n",
    "\n",
    "opt_hidden = netD.init_hidden(batchSize)\n",
    "# opt_hidden.cuda()\n",
    "opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "# opt_hidden[0].data.cuda()\n",
    "# opt_hidden[1].data.cuda()\n",
    "# opt_hidden = torch.LongTensor(opt_hidden)\n",
    "# print(opt_hidden.shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-4.5521 -4.5705 -4.6419 -4.8045 -4.5677 -4.5999 -4.5804 -4.6117 -4.5726 -4.5917\n",
       "\n",
       "Columns 10 to 19 \n",
       "-4.5973 -4.5835 -4.5705 -4.5725 -4.5961 -4.6222 -4.5328 -4.5503 -4.5898 -4.5885\n",
       "\n",
       "Columns 20 to 29 \n",
       "-4.5469 -4.5391 -4.5667 -4.5361 -4.5709 -4.5696 -4.6104 -4.7213 -4.6088 -4.5216\n",
       "\n",
       "Columns 30 to 39 \n",
       "-4.6037 -4.5606 -4.5954 -4.5949 -4.6736 -4.7306 -4.5845 -4.6053 -4.5730 -4.6299\n",
       "\n",
       "Columns 40 to 49 \n",
       "-4.6218 -4.6475 -4.5720 -4.6258 -4.6414 -4.6156 -4.5857 -4.5737 -4.7474 -4.6610\n",
       "\n",
       "Columns 50 to 59 \n",
       "-4.5990 -4.5726 -4.6037 -4.5704 -4.6866 -4.5332 -4.5863 -4.5536 -4.6362 -4.5944\n",
       "\n",
       "Columns 60 to 69 \n",
       "-4.5762 -4.6348 -4.5757 -4.5579 -4.5767 -4.6664 -4.5749 -4.7380 -4.6260 -4.7236\n",
       "\n",
       "Columns 70 to 79 \n",
       "-4.5654 -4.6133 -4.6119 -4.5921 -4.6001 -4.5623 -4.5898 -4.6914 -4.5245 -4.5913\n",
       "\n",
       "Columns 80 to 89 \n",
       "-4.5685 -4.5399 -4.6567 -4.5368 -4.7254 -4.5940 -4.5314 -4.6590 -4.5693 -4.7102\n",
       "\n",
       "Columns 90 to 99 \n",
       "-4.5839 -4.7046 -4.7127 -4.6402 -4.5838 -4.6107 -4.5689 -4.5613 -4.7212 -4.6354\n",
       "[torch.cuda.FloatTensor of size 1x100 (GPU 0)]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Val Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del img_input, ques_input, his_input, ans_input, ans_target, wrong_ans_input, opt_ans_input, batch_sample_idx\n",
    "# del fake_diff_mask, fake_len, noise_input, gt_index\n",
    "# %reset \n",
    "img_input = torch.FloatTensor(batchSize)\n",
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "\n",
    "# answer input\n",
    "ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "ans_target = torch.LongTensor(ans_length, batchSize)\n",
    "wrong_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "sample_ans_input = torch.LongTensor(1, batchSize)\n",
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "\n",
    "batch_sample_idx = torch.LongTensor(batchSize)\n",
    "fake_diff_mask = torch.ByteTensor(batchSize)\n",
    "fake_len = torch.LongTensor(batchSize)\n",
    "noise_input = torch.FloatTensor(batchSize)\n",
    "gt_index = torch.LongTensor(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    ques_input, his_input, img_input = ques_input.cuda(), his_input.cuda(), img_input.cuda()\n",
    "    ans_input, ans_target = ans_input.cuda(), ans_target.cuda()\n",
    "    wrong_ans_input = wrong_ans_input.cuda()\n",
    "    sample_ans_input = sample_ans_input.cuda()\n",
    "\n",
    "    fake_len = fake_len.cuda()\n",
    "    noise_input = noise_input.cuda()\n",
    "    batch_sample_idx = batch_sample_idx.cuda()\n",
    "    fake_diff_mask = fake_diff_mask.cuda()\n",
    "    opt_ans_input = opt_ans_input.cuda()\n",
    "    gt_index = gt_index.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ques_input = Variable(ques_input)\n",
    "img_input = Variable(img_input)\n",
    "his_input = Variable(his_input)\n",
    "\n",
    "ans_input = Variable(ans_input)\n",
    "ans_target = Variable(ans_target)\n",
    "wrong_ans_input = Variable(wrong_ans_input)\n",
    "sample_ans_input = Variable(sample_ans_input)\n",
    "\n",
    "noise_input = Variable(noise_input)\n",
    "batch_sample_idx = Variable(batch_sample_idx)\n",
    "fake_diff_mask = Variable(fake_diff_mask)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "gt_index = Variable(gt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 0.0004\n",
    "beta1 = 0.8\n",
    "log_interval = 50\n",
    "optimizer = optim.Adam([{'params': netW.parameters()},\n",
    "                        {'params': netE.parameters()},\n",
    "                        {'params': netD.parameters()}], lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('currLoss:', Variable containing:\n",
      " 4.5886\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5981\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6374\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6523\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6730\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5619\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5938\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5661\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6591\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5465\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6444\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5944\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6195\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6178\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5598\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.4881\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6501\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6533\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6604\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.4789\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6838\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6143\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5698\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6373\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6093\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5991\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6664\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6990\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5615\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6613\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6396\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6148\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6293\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6390\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6301\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5962\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6337\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6014\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5717\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5856\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6341\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6423\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6203\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6469\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5965\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6083\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6090\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5797\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6350\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5895\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5989\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5580\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6651\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.7592\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.4984\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.7291\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6416\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5880\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5681\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6118\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6214\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5790\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5558\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5803\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5882\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6116\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6166\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6066\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5697\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5539\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.7211\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5723\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6029\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5988\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6083\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6187\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6143\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5503\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6480\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5995\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5869\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5234\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6667\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6113\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5450\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.7756\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5826\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6360\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6100\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.7278\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5897\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5587\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6268\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6233\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5957\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5257\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6492\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6575\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6644\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6367\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5895\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6433\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6053\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5751\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6260\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.7131\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6423\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6287\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6216\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5911\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5900\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6382\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5278\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6678\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6654\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5658\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6529\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6609\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6436\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5315\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6290\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5870\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6631\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6868\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6750\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.5709\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6131\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6016\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('currLoss:', Variable containing:\n",
      " 4.6134\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-74f91eb5c1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-241-7033efebcadf>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m#             print(currLoss.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m#             print(currLoss[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mcurrLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "critD = nn.NLLLoss()\n",
    "\n",
    "if enCuda:\n",
    "    critD.cuda()\n",
    "\n",
    "# netW.cuda()\n",
    "epoch = 0\n",
    "\n",
    "trainModel(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 1/40504  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/40504: mrr: 0.030136 R1: 0.000000 R5 0.020000 R10 0.030000 Mean 51.790000\n"
     ]
    }
   ],
   "source": [
    "rank_all = valModel()\n",
    "epoch = 1\n",
    "R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ebf257d4464a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;34m'netD'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     'netE': netE.state_dict()},\n\u001b[0;32m----> 6\u001b[0;31m                     '%s/epoch_%d.pth' % (save_path, epoch))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_path' is not defined"
     ]
    }
   ],
   "source": [
    "# save_path = '~/notebooks/save'\n",
    "torch.save({'epoch': epoch,\n",
    "                    'netW': netW.state_dict(),\n",
    "                    'netD': netD.state_dict(),\n",
    "                    'netE': netE.state_dict()},\n",
    "                    '%s/epoch_%d.pth' % (save_path, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_path = ''\n",
    "# model_path = save_path\n",
    "model_path = './save/D.15-4-16/epoch_1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './save/D.15-4-16/epoch_1.pth'\n"
     ]
    }
   ],
   "source": [
    "outf = './save'\n",
    "decoder = 'D'\n",
    "\n",
    "if model_path != '':\n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    batchSize = 1\n",
    "else:\n",
    "    # create new folder.\n",
    "    t = datetime.datetime.now()\n",
    "    cur_time = '%s-%s-%s' %(t.day, t.month, t.hour)\n",
    "    save_path = os.path.join(outf, decoder + '.' + cur_time)\n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_path != '': # load the pre-trained model.\n",
    "    netW.load_state_dict(checkpoint['netW'])\n",
    "    netE.load_state_dict(checkpoint['netE'])\n",
    "    netD.load_state_dict(checkpoint['netD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20 / 4051 (epoch 0), average loss 4.614, lr = 0.000400\n",
      "step 40 / 4051 (epoch 0), average loss 4.610, lr = 0.000400\n",
      "step 60 / 4051 (epoch 0), average loss 4.610, lr = 0.000400\n",
      "step 80 / 4051 (epoch 0), average loss 4.613, lr = 0.000400\n",
      "step 100 / 4051 (epoch 0), average loss 4.612, lr = 0.000400\n",
      "step 120 / 4051 (epoch 0), average loss 4.610, lr = 0.000400\n",
      "step 140 / 4051 (epoch 0), average loss 4.612, lr = 0.000400\n",
      "step 160 / 4051 (epoch 0), average loss 4.610, lr = 0.000400\n",
      "step 180 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 200 / 4051 (epoch 0), average loss 4.615, lr = 0.000400\n",
      "step 220 / 4051 (epoch 0), average loss 4.609, lr = 0.000400\n",
      "step 240 / 4051 (epoch 0), average loss 4.613, lr = 0.000400\n",
      "step 260 / 4051 (epoch 0), average loss 4.612, lr = 0.000400\n",
      "step 280 / 4051 (epoch 0), average loss 4.612, lr = 0.000400\n",
      "step 300 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 320 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 340 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 360 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 380 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 400 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 420 / 4051 (epoch 0), average loss 4.613, lr = 0.000400\n",
      "step 440 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 460 / 4051 (epoch 0), average loss 4.610, lr = 0.000400\n",
      "step 480 / 4051 (epoch 0), average loss 4.609, lr = 0.000400\n",
      "step 500 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 520 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 540 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 560 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 580 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 600 / 4051 (epoch 0), average loss 4.608, lr = 0.000400\n",
      "step 620 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 640 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 660 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 680 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 700 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 720 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 740 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 760 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 780 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 800 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 820 / 4051 (epoch 0), average loss 4.607, lr = 0.000400\n",
      "step 840 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 860 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 880 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 900 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 920 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 940 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 960 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 980 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1000 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1020 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1040 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1060 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1080 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1100 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1120 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1140 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1160 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1180 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1200 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1220 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1240 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1260 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1280 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1300 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1320 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1340 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1360 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1380 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1400 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1420 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1440 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1460 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1480 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1500 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1520 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1540 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1560 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1580 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1600 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1620 / 4051 (epoch 0), average loss 4.604, lr = 0.000400\n",
      "step 1640 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1660 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1680 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1700 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1720 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1740 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1760 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1780 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1800 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 1820 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1840 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1860 / 4051 (epoch 0), average loss 4.623, lr = 0.000400\n",
      "step 1880 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1900 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1920 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1940 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1960 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 1980 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2000 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2020 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2040 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2060 / 4051 (epoch 0), average loss 4.709, lr = 0.000400\n",
      "step 2080 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2100 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2120 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2140 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2160 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2180 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2200 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2220 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2240 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2260 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2280 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 2300 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2320 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2340 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2360 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2380 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2400 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 2420 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2440 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2460 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2480 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2500 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2520 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2540 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2560 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2580 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2600 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2620 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2640 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2660 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2680 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 2700 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 2720 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2740 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2760 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2780 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2800 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2820 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2840 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2860 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2880 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2900 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2920 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2940 / 4051 (epoch 0), average loss 4.663, lr = 0.000400\n",
      "step 2960 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 2980 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3000 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3020 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3040 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3060 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3080 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3100 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3120 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3140 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3160 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3180 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3200 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3220 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3240 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3260 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3280 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3300 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3320 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3340 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3360 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3380 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3400 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3420 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3440 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3460 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3480 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3500 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 3520 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3540 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3560 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3580 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3600 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3620 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3640 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3660 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3680 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3700 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3720 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3740 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3760 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3780 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3800 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3820 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3840 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3860 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3880 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3900 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3920 / 4051 (epoch 0), average loss 4.606, lr = 0.000400\n",
      "step 3940 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3960 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 3980 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 4000 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 4020 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "step 4040 / 4051 (epoch 0), average loss 4.605, lr = 0.000400\n",
      "Epoch: 0 learningRate 0.000400 train loss 506.566980 Time: 3641.557379\n",
      "Evaluating ... \n",
      "0/40504: mrr: 0.026728 R1: 0.000000 R5 0.010000 R10 0.020000 Mean 51.160000\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '~/notebooks/saved_checkpoints/epoch_0.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-329-2f5afb490875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;34m'netD'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     'netE': netE.state_dict()},\n\u001b[0;32m---> 45\u001b[0;31m                     '%s/epoch_%d.pth' % (save_path, epoch))\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/log.json'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mto\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '~/notebooks/saved_checkpoints/epoch_0.pth'"
     ]
    }
   ],
   "source": [
    "lr = 0.0004\n",
    "beta1 = 0.8\n",
    "niter = 5\n",
    "neg_batch_sample = 30 \n",
    "log_interval = 20\n",
    "save_iter = 1\n",
    "save_path = '~/notebooks/saved_checkpoints'\n",
    "optimizer = optim.Adam([{'params': netW.parameters()},\n",
    "                        {'params': netE.parameters()},\n",
    "                        {'params': netD.parameters()}], lr=lr, betas=(beta1, 0.999))\n",
    "enCuda = 1\n",
    "\n",
    "if enCuda:\n",
    "    torch.cuda.manual_seed(manualSeed)\n",
    "    \n",
    "critD = nn.NLLLoss()\n",
    "if enCuda:\n",
    "    critD.cuda()\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(niter):\n",
    "    t = time.time()\n",
    "    train_loss = trainModel(epoch)\n",
    "    print ('Epoch: %d learningRate %4f train loss %4f Time: %3f' % (epoch, lr, train_loss, time.time()-t))\n",
    "    train_his = {'loss': train_loss}\n",
    "\n",
    "    print('Evaluating ... ')\n",
    "    rank_all = valModel()\n",
    "    R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "    R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "    R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "    ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "    mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "    print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))\n",
    "    val_his = {'R1': R1, 'R5':R5, 'R10': R10, 'Mean':ave, 'mrr':mrr}\n",
    "    history.append({'epoch':epoch, 'train': train_his, 'val': val_his})\n",
    "\n",
    "#     saving the model.\n",
    "    if epoch % save_iter == 0:\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'netW': netW.state_dict(),\n",
    "                    'netD': netD.state_dict(),\n",
    "                    'netE': netE.state_dict()},\n",
    "                    '%s/epoch_%d.pth' % (save_path, epoch))\n",
    "\n",
    "        json.dump(history, open('%s/log.json' %(save_path), 'w'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
