{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import time\n",
    "import pdb\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2016 NVIDIA Corporation\r\n",
      "Built on Sun_Sep__4_22:14:01_CDT_2016\r\n",
      "Cuda compilation tools, release 8.0, V8.0.44\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at torch/csrc/cuda/Module.cpp:131",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-35e676d96af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \"\"\"\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at torch/csrc/cuda/Module.cpp:131"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Seed: ', 5013)\n"
     ]
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000) # fix seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netE(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, dropout, img_feat_size):\n",
    "        super(_netE, self).__init__()\n",
    "\n",
    "        self.d = dropout\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.nhid = nhid\n",
    "        self.ninp = ninp\n",
    "        self.img_feat_size = img_feat_size\n",
    "\n",
    "        self.img_embed = nn.Linear(img_feat_size, nhid)\n",
    "        self.ques_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "        self.his_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "\n",
    "        self.Wq_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wh_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wi_1 = nn.Linear(self.img_feat_size, self.nhid)\n",
    "        self.Wa_1 = nn.Linear(self.nhid, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.nhid*3, self.ninp)\n",
    "\n",
    "    def forward(self, ques_emb, his_emb, img_raw, ques_hidden, his_hidden, rnd):\n",
    "\n",
    "        img_emb = F.tanh(self.img_embed(img_raw))\n",
    "        ques_feat, ques_hidden = self.ques_rnn(ques_emb, ques_hidden)\n",
    "        ques_feat = ques_feat[-1]\n",
    "        his_feat, his_hidden = self.his_rnn(his_emb, his_hidden)\n",
    "        his_feat = his_feat[-1]\n",
    "\n",
    "        ques_emb_1 = self.Wq_1(ques_feat).view(-1, 1, self.nhid)\n",
    "        his_emb_1 = self.Wh_1(his_feat).view(-1, rnd, self.nhid)\n",
    "        his_cat = his_emb_1.mean(1)\n",
    "\n",
    "        img_cat = img_emb.view(-1,49,self.nhid)\n",
    "        img_cat = img_cat.mean(1)\n",
    "        \n",
    "        concat_feat = torch.cat((ques_feat, his_cat.view(-1, self.nhid), \\\n",
    "                                 img_cat.view(-1, self.nhid)),1)\n",
    "        \n",
    "        encoder_feat = F.tanh(self.fc1(F.dropout(concat_feat, self.d, training=self.training)))\n",
    "\n",
    "        return encoder_feat, ques_hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "#             e = 1\n",
    "#             return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "            return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                    Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####CHANGE CUDA\n",
    "\n",
    "class _netW(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, dropout):\n",
    "        super(_netW, self).__init__()\n",
    "        self.word_embed = nn.Embedding(ntoken+1, ninp).cuda()\n",
    "        self.word_embed = nn.Embedding(ntoken+1, ninp)\n",
    "        self.Linear = share_Linear(self.word_embed.weight).cuda()\n",
    "        self.word_embed = nn.Embedding(ntoken+1, ninp)\n",
    "        self.Linear = share_Linear(self.word_embed.weight)\n",
    "        self.init_weights()\n",
    "        self.d = dropout\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.word_embed.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, format ='index'):\n",
    "        if format == 'onehot':\n",
    "            out = F.dropout(self.Linear(input), self.d, training=self.training)\n",
    "        elif format == 'index':\n",
    "            out = F.dropout(self.word_embed(input), self.d, training=self.training)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            #netW\n",
    "            w = 1\n",
    "            return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                    Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    \"\"\"\n",
    "    Given the real/wrong/fake answer, use a RNN (LSTM) to embed the answer.\n",
    "    \"\"\"\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, ntoken, dropout):\n",
    "        super(_netD, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.ntoken = ntoken\n",
    "        self.ninp = ninp\n",
    "        self.d = dropout\n",
    "\n",
    "        self.ans_rnn = nn.LSTM(self.ninp, self.ninp, self.nlayers)\n",
    "        self.W2 = nn.Linear(self.nhid, 1)\n",
    "        self.fc = nn.Linear(nhid, ninp)\n",
    "\n",
    "    def forward(self, input_feat, hidden, opt_ans_emb, vocab_size):\n",
    "\n",
    "        # opt_ans_emb = self.ans_emb(opt_ans.view(-1,200,9))\n",
    "        output, _ = self.ans_rnn(opt_ans_emb, hidden)\n",
    "        output = output[-1]\n",
    "        output = output.view(100,-1,self.ninp)        \n",
    "        # redOutput = output.mean(1).view(100,self.ninp,-1)\n",
    "        output_feat = output.view(100,self.ninp,-1)\n",
    "        expand_feat = input_feat.view(-1,1,self.ninp)\n",
    "        print('expand feat', expand_feat.size())\n",
    "        print('output_feat',output_feat.size())\n",
    "        prob = F.softmax(torch.bmm(expand_feat,output_feat)).view(100,-1)\n",
    "\n",
    "        return prob\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            #netD\n",
    "            d = 1\n",
    "            return (Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()),\n",
    "                    Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.ninp).zero_())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h, batch_size):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data.resize_(h.size(0), batch_size, h.size(2)).zero_())\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v, batch_size) for v in h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class train(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "            \n",
    "        self.img_info = self.img_info[s:e]\n",
    "\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # get the image\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ques_ori = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, self.negative_sample, self.ans_length+1))\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, self.negative_sample))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        ans_idx = np.zeros((self.rnd))\n",
    "        opt_ans_idx = np.zeros((self.rnd, self.negative_sample))\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                his[i+1, self.his_length-qa_len:self.his_length-a_len] = self.ques[index, i, :q_len]\n",
    "                his[i+1, self.his_length-a_len:] = self.ans[index, i, :a_len]\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "\n",
    "            ques_ori[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            # random select the negative samples.\n",
    "            ans_idx[i] = opt_ids[self.ans_ids[index, i]]\n",
    "            # exclude the gt index.\n",
    "            opt_ids = np.delete(opt_ids, ans_idx[i], 0)\n",
    "            random.shuffle(opt_ids)\n",
    "            for j in range(self.negative_sample):\n",
    "                ids = opt_ids[j]\n",
    "                opt_ans_idx[i,j] = ids\n",
    "\n",
    "                opt_len = self.opt_len[ids]\n",
    "\n",
    "                opt_ans_len[i, j] = opt_len\n",
    "                opt_ans[i, j, :opt_len] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, opt_len] = self.vocab_size\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        ques_ori = torch.from_numpy(ques_ori)\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        ans_idx = torch.from_numpy(ans_idx)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "        opt_ans_idx = torch.from_numpy(opt_ans_idx)\n",
    "        return img, his, ques, ans, ans_target, ans_len, ans_idx, ans_ids, ques_ori, \\\n",
    "                opt_ans, opt_ans_len, opt_ans_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class validate(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "\n",
    "        self.img_info = self.img_info[s:e]\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "###########################################################################################\n",
    "#CHANGE THIS HERE FOR NON DEMO TRAINING SET\n",
    "        split = 'train'\n",
    "###########################################################################################\n",
    "        \n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # get the image\n",
    "        img_id = self.img_info[index]['imgId']\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        quesL = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        opt_ans_target = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, 100))\n",
    "\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                ques_ans = np.concatenate([self.ques[index, i, :q_len], self.ans[index, i, :a_len]])\n",
    "                his[i+1, self.his_length-qa_len:] = ques_ans\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "            quesL[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_idx = self.ans_ids[index, i]\n",
    "\n",
    "            for j, ids in enumerate(opt_ids):\n",
    "                opt_len = self.opt_len[ids]\n",
    "                opt_ans[i, j, 1:opt_len+1] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, 0] = self.vocab_size\n",
    "\n",
    "                opt_ans_target[i, j,:opt_len] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans_target[i, j,opt_len] = self.vocab_size\n",
    "                opt_ans_len[i, j] = opt_len\n",
    "\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        opt_ans_target = torch.from_numpy(opt_ans_target)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        quesL = torch.from_numpy(quesL)\n",
    "\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "\n",
    "        return img, his, ques, ans, ans_target, quesL, opt_ans, \\\n",
    "                    opt_ans_target, ans_ids, ans_len, opt_ans_len, img_id\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(epoch):\n",
    "    netW.train()\n",
    "    netE.train()\n",
    "    netD.train()\n",
    "\n",
    "#     lr = adjust_learning_rate(optimizer, epoch, opt.lr)\n",
    "\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "#     wrong_hidden = netD.init_hidden(batchSize)\n",
    "\n",
    "    data_iter = iter(dloader)\n",
    "\n",
    "    average_loss = 0\n",
    "    count = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(dloader):\n",
    "\n",
    "        t1 = time.time()\n",
    "        data = data_iter.next()\n",
    "        image, history, question, answer, answerT, answerLen, answerIdx, answerIds, questionL, \\\n",
    "                                    opt_answerT, opt_answerLen, opt_answerIdx = data\n",
    "\n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            netW.zero_grad()\n",
    "            netE.zero_grad()\n",
    "            netD.zero_grad()\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            ans = answer[:,rnd,:].t()\n",
    "            tans = answerT[:,rnd,:].t()\n",
    "#             wrong_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "\n",
    "#             real_len = answerLen[:,rnd]\n",
    "#             wrong_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            ans_input.data.resize_(ans.size()).copy_(ans)\n",
    "            ans_target.data.resize_(tans.size()).copy_(tans)\n",
    "#             wrong_ans_input.data.resize_(wrong_ans.size()).copy_(wrong_ans)\n",
    "\n",
    "            # sample in-batch negative index\n",
    "#             batch_sample_idx.data.resize_(batch_size, neg_batch_sample).zero_()\n",
    "#             sample_batch_neg(answerIdx[:,rnd], opt_answerIdx[:,rnd,:], batch_sample_idx, neg_batch_sample)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "            print('img input size:', img_input.size())\n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "#             ans_real_emb = netW(ans_target, format='index')\n",
    "#             ans_wrong_emb = netW(wrong_ans_input, format='index')\n",
    "\n",
    "#             real_hidden = repackage_hidden(real_hidden, batch_size)\n",
    "#             wrong_hidden = repackage_hidden(wrong_hidden, ans_wrong_emb.size(1))\n",
    "\n",
    "#             real_feat = netD(ans_real_emb, ans_target, real_hidden, vocab_size)\n",
    "#             wrong_feat = netD(ans_wrong_emb, wrong_ans_input, wrong_hidden, vocab_size)\n",
    "\n",
    "#             batch_wrong_feat = wrong_feat.index_select(0, batch_sample_idx.view(-1))\n",
    "#             wrong_feat = wrong_feat.view(batch_size, -1, ninp)\n",
    "#             batch_wrong_feat = batch_wrong_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "#             nPairLoss = critD(featD, real_feat, wrong_feat, batch_wrong_feat)\n",
    "\n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "\n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "\n",
    "            opt_hidden = netD.init_hidden(batchSize)\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "            # print(opt_hidden.shape())\n",
    "            prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "            optIdx = opt_answerIdx[:,rnd,:]\n",
    "            # print(optIdx.size())\n",
    "            ansIds = answerIds[:,rnd]\n",
    "            ansIds = ansIds.long()\n",
    "            ansIds = Variable(ansIds, requires_grad = False)\n",
    "            ansIds = ansIds.cuda()\n",
    "#             print(ansIdx.size())\n",
    "#             b_no = 0\n",
    "#             ans_list = []\n",
    "            \n",
    "#             for elem in ansIdx:\n",
    "#                 t = ((optIdx[b_no,:]==elem).nonzero())\n",
    "#             #     print(t.size())\n",
    "#                 if (t.size()!=torch.Size([])):\n",
    "#                     ans_list.append(t[0][0])\n",
    "#                 else:\n",
    "#                     ans_list.append((-1))\n",
    "    \n",
    "#                 b_no = b_no + 1\n",
    "\n",
    "#             corr_ans_ind = torch.LongTensor(ans_list)\n",
    "            \n",
    "\n",
    "#             corr_ans_ind = Variable(corr_ans_ind)\n",
    "#             corr_ans_ind = corr_ans_ind.cuda()\n",
    "\n",
    "            currLoss = critD(prob,ansIds)\n",
    "#             print(currLoss)\n",
    "#             average_loss += currLoss.data[0]\n",
    "            currLoss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "\n",
    "        i += 1\n",
    "        if i % log_interval == 0:\n",
    "            average_loss /= count\n",
    "            print(\"step {} / {} (epoch {}), g_loss {:.3f}, lr = {:.6f}\"\\\n",
    "                .format(i, len(dataloader), epoch, average_loss, lr))\n",
    "            average_loss = 0\n",
    "            count = 0\n",
    "\n",
    "    return average_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valModel():\n",
    "    netE.eval()\n",
    "    netW.eval()\n",
    "    netD.eval()\n",
    "\n",
    "#     n_neg = 100\n",
    "    data_iter_val = iter(dataloader_val)\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "    i = 0\n",
    "\n",
    "    average_loss = 0\n",
    "    rank_all_tmp = []\n",
    "\n",
    "    while i < len(dataloader_val):\n",
    "        data = data_iter_val.next()\n",
    "        image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answer_ids, answerLen, opt_answerLen, img_id  = data\n",
    "\n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "        #image = l2_norm(image)\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            gt_id = answer_ids[:,rnd]\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "            gt_index.data.resize_(gt_id.size()).copy_(gt_id)\n",
    "            opt_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "\n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "            score = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "            \n",
    "#             opt_feat = opt_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "            #ans_emb = ans_emb.view(ans_length, -1, 100, opt.nhid)\n",
    "#             featD = featD.view(-1, ninp, 1)\n",
    "#             score = torch.bmm(opt_feat, featD)\n",
    "#             score = score.view(-1, 100)\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                gt_index.data[b] = gt_index.data[b] + b*100\n",
    "\n",
    "            gt_score = score.view(-1).index_select(0, gt_index)\n",
    "            sort_score, sort_idx = torch.sort(score, 1, descending=True)\n",
    "\n",
    "            count = sort_score.gt(gt_score.view(-1,1).expand_as(sort_score))\n",
    "            rank = count.sum(1) + 1\n",
    "            rank_all_tmp += list(rank.view(-1).data.cpu().numpy())\n",
    "            \n",
    "        i += 1\n",
    "        sys.stdout.write('Evaluating: {:d}/{:d}  \\r' \\\n",
    "          .format(i, len(dataloader_val)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return rank_all_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class share_Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = Ax + b`\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias. Default: True\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in\\_features)`\n",
    "        - Output: :math:`(N, out\\_features)`\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape (out_features x in_features)\n",
    "        bias:   the learnable bias of the module of shape (out_features)\n",
    "    Examples::\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = autograd.Variable(torch.randn(128, 20))\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight):\n",
    "        super(share_Linear, self).__init__()\n",
    "        self.in_features = weight.size(0)\n",
    "        self.out_features = weight.size(1)\n",
    "        self.weight = weight.t()\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + str(self.in_features) + ' -> ' \\\n",
    "            + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'LSTM'\n",
    "ninp = 300\n",
    "nhid = 512\n",
    "nlayers = 1\n",
    "dropout = 0.5\n",
    "margin = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Here for input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: train\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "train number of data: 81783\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "# input_img_h5 = 'vdl_img_vgg_demo.h5'\n",
    "# input_ques_h5 = 'visdial_data_demo.h5'\n",
    "input_img_h5 = 'vdl_img_vgg.h5'\n",
    "input_ques_h5 = 'visdial_data.h5'\n",
    "input_json = 'visdial_params.json'\n",
    "negative_sample = 20\n",
    "num_val = 1000\n",
    "dataset = train(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: test\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "test number of data: 40504\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "dataset_val = validate(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "num_workers = 0\n",
    "dloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=int(num_workers))\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=1,\n",
    "                                         shuffle=False, num_workers=int(num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_iter1 = iter(dloader)\n",
    "data = data_iter1.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image, history, question, answer, answerT, answerLen, answerIdx, answerIds, questionL, \\\n",
    "        opt_answerT, opt_answerLen, opt_answerIdx = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd = 3\n",
    "ques_length = dataset.ques_length\n",
    "negative_sample = 20\n",
    "n_neg = negative_sample\n",
    "vocab_size = dataset.vocab_size\n",
    "ques_length = dataset.ques_length\n",
    "ans_length = dataset.ans_length + 1\n",
    "his_length = dataset.ans_length + dataset.ques_length\n",
    "itow = dataset.itow\n",
    "img_feat_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8964"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nThe NVIDIA driver on your system is too old (found version 8000).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: http://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5d5c190ba81a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_netW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mninp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-69f1d6dbaf61>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ntoken, ninp, dropout)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mninp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_netW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntoken\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mninp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntoken\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mninp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshare_Linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m         raise RuntimeError(\n\u001b[1;32m    140\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mAlternatively\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m \u001b[0mto\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0myour\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m of the CUDA driver.\"\"\".format(str(torch._C._cuda_getDriverVersion())))\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nThe NVIDIA driver on your system is too old (found version 8000).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: http://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver."
     ]
    }
   ],
   "source": [
    "netW = _netW(vocab_size, ninp, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netE = _netE(model, ninp, nhid, nlayers, dropout, img_feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netE.cuda()\n",
    "netW.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nThe NVIDIA driver on your system is too old (found version 8000).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: http://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ed88073f7acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mques_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mques_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mques_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mques_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m         raise RuntimeError(\n\u001b[1;32m    140\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mAlternatively\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m \u001b[0mto\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0myour\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m of the CUDA driver.\"\"\".format(str(torch._C._cuda_getDriverVersion())))\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nThe NVIDIA driver on your system is too old (found version 8000).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: http://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver."
     ]
    }
   ],
   "source": [
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "ques_input = Variable(ques_input)\n",
    "ques = question[:,rnd,:].t()\n",
    "ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "ques_input = ques_input.cuda()\n",
    "ques_emb = netW(ques_input, format = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = image.view(-1, img_feat_size)\n",
    "img_input = torch.FloatTensor(batchSize)\n",
    "img_input = Variable(img_input)\n",
    "img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "his_input = Variable(his_input)\n",
    "his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "his_input.data.resize_(his.size()).copy_(his)\n",
    "his_input = his_input.cuda()\n",
    "his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "batch_size = question.size(0)\n",
    "\n",
    "ques_hidden = netE.init_hidden(batchSize)\n",
    "hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4900, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_input.size()\n",
    "# image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/backends/cudnn/__init__.py:40: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "netE.cuda()\n",
    "netW.cuda()\n",
    "img_input = img_input.cuda()\n",
    "ques_emb = ques_emb.cuda()\n",
    "his_emb = his_emb.cuda()\n",
    "\n",
    "featD, ques_hidden = netE(ques_emb, his_emb, img_input, ques_hidden, hist_hidden, rnd+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10, 20, 9])\n",
      "torch.Size([9, 20000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected a Variable argument, but got torch.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4254dc8fee99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-69f1d6dbaf61>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, format)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/sparse.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         )(input, self.weight)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected a Variable argument, but got torch.LongTensor"
     ]
    }
   ],
   "source": [
    "print(opt_answerT.size())\n",
    "# t = torch.LongTensor(opt_answerT)\n",
    "# print('t size',t[0].view(9,-1).size())\n",
    "t = opt_answerT.long()\n",
    "temp = t.view(-1,9).t()\n",
    "print(temp.size())\n",
    "emb = netW(temp, format = 'index')\n",
    "emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "torch.Size([16, 100, 300])\n"
     ]
    }
   ],
   "source": [
    "opt_answerLen.size()\n",
    "print(ques_input.size())\n",
    "# his_input.size()\n",
    "ques_emb = netW(ques_input, format = 'index')\n",
    "print(ques_emb.size())\n",
    "# his_emb = netW(his_input, format = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor([[2,2],[2,2]])\n",
    "b = a - 1\n",
    "b = a.unsqueeze(-1)\n",
    "b = a.expand(2,2,2)\n",
    "b[0][1] *=2\n",
    "# a[0]\n",
    "# print(b)\n",
    "c = b.unsqueeze(-1)\n",
    "c = b.expand(3,2,2,2)\n",
    "# c.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns 0 to 5 \n",
      " 1.8902e+04  7.1412e+04  5.4282e+04  1.2387e+05  1.7612e+05  1.6521e+05\n",
      " 2.2308e+05  3.5196e+04  2.1391e+05  7.8387e+04  1.2205e+05  2.2836e+04\n",
      " 7.4224e+04  1.5295e+05  1.2205e+05  3.5710e+04  2.3314e+05  4.7583e+04\n",
      " 1.1093e+05  1.5046e+05  4.4150e+04  9.1056e+04  1.6145e+05  2.6702e+04\n",
      " 1.7095e+05  2.2009e+05  7.4224e+04  9.8037e+04  1.1651e+05  2.0549e+05\n",
      " 4.9191e+04  4.0882e+04  1.0184e+05  1.7653e+05  2.3744e+05  1.6056e+05\n",
      " 1.0410e+05  8.2426e+04  2.1403e+05  2.5105e+05  1.8959e+05  1.7604e+05\n",
      " 2.0889e+05  8.0082e+04  7.9823e+04  1.4115e+05  7.2807e+04  9.9828e+04\n",
      " 1.4078e+05  9.8046e+04  1.6878e+04  2.4621e+05  1.2452e+05  5.2650e+04\n",
      " 2.1887e+05  6.0361e+04  1.9780e+05  2.0731e+05  1.8762e+05  4.0882e+04\n",
      "\n",
      "Columns 6 to 11 \n",
      " 6.9593e+04  6.6072e+04  5.4696e+04  4.6490e+03  9.4076e+04  8.0082e+04\n",
      " 7.4224e+04  5.3300e+04  2.2901e+05  2.2082e+05  8.5776e+04  1.9780e+05\n",
      " 7.8387e+04  1.2489e+05  1.9592e+05  2.2273e+05  2.1123e+05  2.2116e+05\n",
      " 1.6182e+05  2.1553e+05  7.1412e+04  2.4933e+05  2.3874e+05  2.0549e+05\n",
      " 2.0015e+05  1.3234e+05  2.4107e+05  1.5279e+05  1.5856e+05  1.5546e+04\n",
      " 2.6088e+04  2.2116e+05  1.6802e+04  2.2476e+04  2.1997e+05  1.2010e+05\n",
      " 6.1698e+04  1.5029e+05  4.5526e+04  4.0882e+04  1.2110e+05  1.3631e+05\n",
      " 7.1727e+04  4.9970e+03  8.4866e+04  1.1656e+05  1.9032e+05  1.1238e+05\n",
      " 1.4578e+05  1.9780e+05  1.9463e+05  9.1056e+04  1.2569e+05  1.6890e+03\n",
      " 2.3529e+05  2.6019e+04  7.4224e+04  1.7938e+05  1.1419e+05  1.8909e+05\n",
      "\n",
      "Columns 12 to 17 \n",
      " 9.0675e+04  1.9309e+05  2.6019e+04  1.6965e+05  1.4214e+05  4.0782e+04\n",
      " 2.0331e+04  9.6489e+04  2.6019e+04  5.7600e+03  1.6436e+05  4.0108e+04\n",
      " 2.2476e+04  1.4039e+05  1.5046e+05  7.3820e+04  3.7658e+04  2.4762e+05\n",
      " 2.2305e+05  2.0068e+05  9.0326e+04  7.1765e+04  7.8387e+04  7.8896e+04\n",
      " 2.6019e+04  1.2158e+04  1.4442e+05  2.4762e+05  5.1860e+04  1.4214e+05\n",
      " 1.5855e+05  1.2738e+05  1.9836e+05  5.0340e+04  1.0086e+04  2.1467e+05\n",
      " 2.0731e+05  5.8752e+04  2.1225e+05  1.4489e+05  9.6154e+04  2.2116e+05\n",
      " 1.3841e+05  1.1354e+05  1.1110e+05  6.4297e+04  8.7260e+03  2.3636e+05\n",
      " 2.0588e+05  7.2905e+04  1.6926e+05  8.8239e+04  4.0882e+04  7.8387e+04\n",
      " 8.7911e+04  2.3670e+05  2.2116e+05  1.8080e+05  1.9527e+05  1.8437e+05\n",
      "\n",
      "Columns 18 to 19 \n",
      " 8.9350e+04  1.2705e+05\n",
      " 3.3386e+04  1.1381e+05\n",
      " 7.4430e+04  4.3867e+04\n",
      " 9.1732e+04  2.4762e+05\n",
      " 1.5295e+05  1.1371e+05\n",
      " 2.1347e+05  8.8808e+04\n",
      " 1.4364e+05  1.3144e+05\n",
      " 1.5131e+04  9.2800e+03\n",
      " 1.7274e+05  1.2564e+05\n",
      " 1.8433e+05  1.0184e+05\n",
      "[torch.DoubleTensor of size 10x20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt_answerIdx.size()\n",
    "print(opt_answerIdx[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: [u'ans_index_train', u'ans_len_train', u'ans_train', u'cap_len_train', u'cap_train', u'opt_len_train', u'opt_list_train', u'opt_train', u'ques_len_train', u'ques_train']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = input_ques_h5\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "# List all groups\n",
    "print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = list(f.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 20, 9])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = opt_answerT.long()\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_netD (\n",
       "  (ans_rnn): LSTM(300, 300)\n",
       "  (W2): Linear (512 -> 1)\n",
       "  (fc): Linear (512 -> 300)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = _netD(model, ninp, nhid, nlayers, vocab_size, dropout)\n",
    "netD.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('expand feat', torch.Size([100, 1, 300]))\n",
      "('output_feat', torch.Size([100, 300, 20]))\n"
     ]
    }
   ],
   "source": [
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "\n",
    "opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "opt_ans_input = opt_ans_input.cuda()\n",
    "\n",
    "opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "\n",
    "opt_hidden = netD.init_hidden(batchSize)\n",
    "opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "# print(opt_hidden.shape())\n",
    "prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ans_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2928462024b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswerT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mans_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ans_target' is not defined"
     ]
    }
   ],
   "source": [
    "tans = answerT[:,rnd,:].t()\n",
    "ans_target.data.resize_(tans.size()).copy_(tans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "[torch.LongTensor of size 100]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optIdx = opt_answerIdx[:,rnd,:]\n",
    "# print(optIdx.size())\n",
    "ansIdx = answerIds[:,rnd]\n",
    "print(ansIdx.size())\n",
    "b_no = 0\n",
    "ans_list = []\n",
    "for elem in ansIdx:\n",
    "    t = ((optIdx[b_no,:]==elem).nonzero())\n",
    "#     print(t.size())\n",
    "    if (t.size()!=(torch.Size([]))):\n",
    "        ans_list.append(t[0][0])\n",
    "    else:\n",
    "        ans_list.append((-1))\n",
    "    \n",
    "    b_no = b_no + 1\n",
    "\n",
    "temp = torch.LongTensor(ans_list)\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optIdx[b_no,:]\n",
    "elem = 23\n",
    "t = (optIdx[b_no,:]==elem).nonzero()\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "t.size()\n",
    "print(ans_list)\n",
    "# torch.LongTensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-32d71e14e96e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "m = nn.LogSoftmax()\n",
    "loss = nn.NLLLoss()\n",
    "temp = Variable(temp)\n",
    "output = loss(prob,temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Val Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = torch.FloatTensor(batchSize)\n",
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "\n",
    "# answer input\n",
    "ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "ans_target = torch.LongTensor(ans_length, batchSize)\n",
    "wrong_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "sample_ans_input = torch.LongTensor(1, batchSize)\n",
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "\n",
    "batch_sample_idx = torch.LongTensor(batchSize)\n",
    "fake_diff_mask = torch.ByteTensor(batchSize)\n",
    "fake_len = torch.LongTensor(batchSize)\n",
    "noise_input = torch.FloatTensor(batchSize)\n",
    "gt_index = torch.LongTensor(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ques_input, his_input, img_input = ques_input.cuda(), his_input.cuda(), img_input.cuda()\n",
    "ans_input, ans_target = ans_input.cuda(), ans_target.cuda()\n",
    "wrong_ans_input = wrong_ans_input.cuda()\n",
    "sample_ans_input = sample_ans_input.cuda()\n",
    "\n",
    "fake_len = fake_len.cuda()\n",
    "noise_input = noise_input.cuda()\n",
    "batch_sample_idx = batch_sample_idx.cuda()\n",
    "fake_diff_mask = fake_diff_mask.cuda()\n",
    "opt_ans_input = opt_ans_input.cuda()\n",
    "gt_index = gt_index.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ques_input = Variable(ques_input)\n",
    "img_input = Variable(img_input)\n",
    "his_input = Variable(his_input)\n",
    "\n",
    "ans_input = Variable(ans_input)\n",
    "ans_target = Variable(ans_target)\n",
    "wrong_ans_input = Variable(wrong_ans_input)\n",
    "sample_ans_input = Variable(sample_ans_input)\n",
    "\n",
    "noise_input = Variable(noise_input)\n",
    "batch_sample_idx = Variable(batch_sample_idx)\n",
    "fake_diff_mask = Variable(fake_diff_mask)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "gt_index = Variable(gt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('img input size:', torch.Size([4900, 512]))\n",
      "('expand feat', torch.Size([100, 1, 300]))\n",
      "('output_feat', torch.Size([100, 300, 20]))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cublas runtime error : the GPU program failed to execute at /opt/conda/conda-bld/pytorch_1501972792122/work/pytorch-0.1.12/torch/lib/THC/THCBlas.cu:246",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2bf24c3b39cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c2e49722191f>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m#             print(currLoss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m#             average_loss += currLoss.data[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mcurrLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    145\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/linear.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mgrad_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cublas runtime error : the GPU program failed to execute at /opt/conda/conda-bld/pytorch_1501972792122/work/pytorch-0.1.12/torch/lib/THC/THCBlas.cu:246"
     ]
    }
   ],
   "source": [
    "critD = nn.NLLLoss()\n",
    "critD.cuda()\n",
    "netW.cuda()\n",
    "epoch = 0\n",
    "\n",
    "trainModel(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('expand feat', torch.Size([1, 1, 300]))\n",
      "('output_feat', torch.Size([100, 300, 1]))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "equal number of batches expected at /opt/conda/conda-bld/pytorch_1501972792122/work/pytorch-0.1.12/torch/lib/THC/generic/THCTensorMathBlas.cu:443",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-38ed9f280b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrank_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mR1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mR5\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mR10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6f3dbc62eafc>\u001b[0m in \u001b[0;36mval\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mopt_ans_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_ans_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mopt_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepackage_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_ans_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_ans_emb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#             opt_feat = opt_feat.view(batch_size, -1, ninp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-86144276b6d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_feat, hidden, opt_ans_emb, vocab_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expand feat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_feat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbmm\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    530\u001b[0m         output = Variable(self.data.new(self.data.size(0), self.data.size(1),\n\u001b[1;32m    531\u001b[0m                                         batch.data.size(2)))\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_static_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaddbmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36m_static_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_args\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/_functions/blas.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, add_batch, batch1, batch2)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         return torch.baddbmm(self.alpha, add_batch, self.beta,\n\u001b[0;32m---> 93\u001b[0;31m                              batch1, batch2, out=output)\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: equal number of batches expected at /opt/conda/conda-bld/pytorch_1501972792122/work/pytorch-0.1.12/torch/lib/THC/generic/THCTensorMathBlas.cu:443"
     ]
    }
   ],
   "source": [
    "rank_all = val()\n",
    "R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0004\n",
    "beta1 = 0.8\n",
    "niter = 5\n",
    "neg_batch_sample = 30 \n",
    "log_interval = 50\n",
    "save_iter = 10000000\n",
    "save_path = '~/notebooks/saved_checkpoints'\n",
    "optimizer = optim.Adam([{'params': netW.parameters()},\n",
    "                        {'params': netE.parameters()},\n",
    "                        {'params': netD.parameters()}], lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(niter):\n",
    "    t = time.time()\n",
    "    train_loss = train(epoch)\n",
    "    print ('Epoch: %d learningRate %4f train loss %4f Time: %3f' % (epoch, lr, train_loss, time.time()-t))\n",
    "    train_his = {'loss': train_loss}\n",
    "\n",
    "    print('Evaluating ... ')\n",
    "    rank_all = val()\n",
    "    R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "    R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "    R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "    ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "    mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "    print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))\n",
    "    val_his = {'R1': R1, 'R5':R5, 'R10': R10, 'Mean':ave, 'mrr':mrr}\n",
    "    history.append({'epoch':epoch, 'train': train_his, 'val': val_his})\n",
    "\n",
    "    saving the model.\n",
    "    if epoch % save_iter == 0:\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'netW': netW.state_dict(),\n",
    "                    'netD': netD.state_dict(),\n",
    "                    'netE': netE.state_dict()},\n",
    "                    '%s/epoch_%d.pth' % (save_path, epoch))\n",
    "\n",
    "        json.dump(history, open('%s/log.json' %(save_path), 'w'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
