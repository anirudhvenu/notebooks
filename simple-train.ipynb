{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? n\n",
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "%reset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import time\n",
    "import pdb\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#             print(ansIdx.size())\n",
    "#             b_no = 0\n",
    "#             ans_list = []\n",
    "            \n",
    "#             for elem in ansIdx:\n",
    "#                 t = ((optIdx[b_no,:]==elem).nonzero())\n",
    "#             #     print(t.size())\n",
    "#                 if (t.size()!=torch.Size([])):\n",
    "#                     ans_list.append(t[0][0])\n",
    "#                 else:\n",
    "#                     ans_list.append((-1))\n",
    "    \n",
    "#                 b_no = b_no + 1\n",
    "\n",
    "#             corr_ans_ind = torch.LongTensor(ans_list)\n",
    "            \n",
    "\n",
    "#             corr_ans_ind = Variable(corr_ans_ind)\n",
    "#             corr_ans_ind = corr_ans_ind.cuda()\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Seed: ', 3428)\n"
     ]
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000) # fix seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enCuda = 1\n",
    "if enCuda:\n",
    "    torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netE(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, dropout, img_feat_size):\n",
    "        super(_netE, self).__init__()\n",
    "\n",
    "        self.d = dropout\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.nhid = nhid\n",
    "        self.ninp = ninp\n",
    "        self.img_feat_size = img_feat_size\n",
    "\n",
    "        self.img_embed = nn.Linear(img_feat_size, nhid)\n",
    "        self.ques_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "        self.his_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "\n",
    "        self.Wq_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wh_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wi_1 = nn.Linear(self.img_feat_size, self.nhid)\n",
    "        self.Wa_1 = nn.Linear(self.nhid, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.nhid*3, self.ninp)\n",
    "\n",
    "    def forward(self, ques_emb, his_emb, img_raw, ques_hidden, his_hidden, rnd):\n",
    "\n",
    "        img_emb = F.tanh(self.img_embed(img_raw))\n",
    "        ques_feat, ques_hidden = self.ques_rnn(ques_emb, ques_hidden)\n",
    "        ques_feat = ques_feat[-1]\n",
    "        his_feat, his_hidden = self.his_rnn(his_emb, his_hidden)\n",
    "        his_feat = his_feat[-1]\n",
    "\n",
    "        ques_emb_1 = self.Wq_1(ques_feat).view(-1, 1, self.nhid)\n",
    "        his_emb_1 = self.Wh_1(his_feat).view(-1, rnd, self.nhid)\n",
    "        his_cat = his_emb_1.mean(1)\n",
    "\n",
    "        img_cat = img_emb.view(-1,49,self.nhid)\n",
    "        img_cat = img_cat.mean(1)\n",
    "        \n",
    "        concat_feat = torch.cat((ques_feat, his_cat.view(-1, self.nhid), \\\n",
    "                                 img_cat.view(-1, self.nhid)),1)\n",
    "        \n",
    "        encoder_feat = F.tanh(self.fc1(F.dropout(concat_feat, self.d, training=self.training)))\n",
    "\n",
    "        return encoder_feat, ques_hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####CHANGE CUDA\n",
    "\n",
    "class _netW(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, dropout):\n",
    "        super(_netW, self).__init__()\n",
    "        self.word_embed = nn.Embedding(ntoken+1, ninp)\n",
    "        self.Linear = share_Linear(self.word_embed.weight)\n",
    "        \n",
    "        if enCuda:\n",
    "            self.word_embed = nn.Embedding(ntoken+1, ninp).cuda()\n",
    "            self.Linear = share_Linear(self.word_embed.weight).cuda()\n",
    "\n",
    "        self.init_weights()\n",
    "        self.d = dropout\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.word_embed.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, format ='index'):\n",
    "        if format == 'onehot':\n",
    "            out = F.dropout(self.Linear(input), self.d, training=self.training)\n",
    "        elif format == 'index':\n",
    "            out = F.dropout(self.word_embed(input), self.d, training=self.training)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    \"\"\"\n",
    "    Given the real/wrong/fake answer, use a RNN (LSTM) to embed the answer.\n",
    "    \"\"\"\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, ntoken, dropout):\n",
    "        super(_netD, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.ntoken = ntoken\n",
    "        self.ninp = ninp\n",
    "        self.d = dropout\n",
    "\n",
    "        self.ans_rnn = nn.LSTM(self.ninp, self.ninp, self.nlayers)\n",
    "        self.W2 = nn.Linear(self.nhid, 1)\n",
    "        self.fc = nn.Linear(nhid, ninp)\n",
    "\n",
    "    def forward(self, input_feat, hidden, opt_ans_emb, vocab_size):\n",
    "\n",
    "        # opt_ans_emb = self.ans_emb(opt_ans.view(-1,200,9))\n",
    "        print(type(hidden[0]))\n",
    "        output, h = self.ans_rnn(opt_ans_emb, hidden)\n",
    "        output = output[-1]\n",
    "#         output = output.view(100,-1,self.ninp)        \n",
    "        # redOutput = output.mean(1).view(100,self.ninp,-1)\n",
    "        output_feat = output.view(-1,100,self.ninp)\n",
    "        expand_feat = input_feat.view(-1,self.ninp,1)\n",
    "\n",
    "#         print('-------------Within Decoder:')\n",
    "#         print('expand feat', expand_feat.size())\n",
    "#         print('output_feat',output_feat.size())\n",
    "        \n",
    "#         feat = output_feat.view(-1,100,1,self.ninp)\n",
    "#         expand_feat = expand_feat.expand(feat.size())\n",
    "#         expand_feat = expand_feat.view(-1,1,self.ninp)\n",
    "        \n",
    "        prob = F.log_softmax(torch.bmm(output_feat,expand_feat)).view(100,-1)\n",
    "\n",
    "        return prob\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.ninp).zero_())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h, batch_size):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data.resize_(h.size(0), batch_size, h.size(2)).zero_())\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v, batch_size) for v in h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class train(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "            \n",
    "        self.img_info = self.img_info[s:e]\n",
    "\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # get the image\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ques_ori = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, self.negative_sample, self.ans_length+1))\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, self.negative_sample))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        ans_idx = np.zeros((self.rnd))\n",
    "        opt_ans_idx = np.zeros((self.rnd, self.negative_sample))\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                his[i+1, self.his_length-qa_len:self.his_length-a_len] = self.ques[index, i, :q_len]\n",
    "                his[i+1, self.his_length-a_len:] = self.ans[index, i, :a_len]\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "\n",
    "            ques_ori[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            # random select the negative samples.\n",
    "            ans_idx[i] = opt_ids[self.ans_ids[index, i]]\n",
    "            # exclude the gt index.\n",
    "            opt_ids = np.delete(opt_ids, ans_idx[i], 0)\n",
    "            random.shuffle(opt_ids)\n",
    "            for j in range(self.negative_sample):\n",
    "                ids = opt_ids[j]\n",
    "                opt_ans_idx[i,j] = ids\n",
    "\n",
    "                opt_len = self.opt_len[ids]\n",
    "                \n",
    "                opt_ans_len[i, j] = opt_len\n",
    "                \n",
    "                opt_ans[i, j, 1:opt_len+1] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, 0] = self.vocab_size\n",
    "                \n",
    "#                 opt_ans[i, j, :opt_len] = self.opt_list[ids,:opt_len]\n",
    "#                 opt_ans[i, j, opt_len] = self.vocab_size\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        ques_ori = torch.from_numpy(ques_ori)\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        ans_idx = torch.from_numpy(ans_idx)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "        opt_ans_idx = torch.from_numpy(opt_ans_idx)\n",
    "        return img, his, ques, ans, ans_target, ans_len, ans_idx, ans_ids, ques_ori, \\\n",
    "                opt_ans, opt_ans_len, opt_ans_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class validate(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "\n",
    "        self.img_info = self.img_info[s:e]\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "###########################################################################################\n",
    "#CHANGE THIS HERE FOR NON DEMO TRAINING SET\n",
    "#         split = 'train'\n",
    "###########################################################################################\n",
    "        \n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # get the image\n",
    "        img_id = self.img_info[index]['imgId']\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        quesL = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        opt_ans_target = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, 100))\n",
    "\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                ques_ans = np.concatenate([self.ques[index, i, :q_len], self.ans[index, i, :a_len]])\n",
    "                his[i+1, self.his_length-qa_len:] = ques_ans\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "            quesL[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_idx = self.ans_ids[index, i]\n",
    "\n",
    "            for j, ids in enumerate(opt_ids):\n",
    "                opt_len = self.opt_len[ids]\n",
    "                opt_ans[i, j, 1:opt_len+1] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, 0] = self.vocab_size\n",
    "\n",
    "                opt_ans_target[i, j,:opt_len] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans_target[i, j,opt_len] = self.vocab_size\n",
    "                opt_ans_len[i, j] = opt_len\n",
    "\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        opt_ans_target = torch.from_numpy(opt_ans_target)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        quesL = torch.from_numpy(quesL)\n",
    "\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "\n",
    "        return img, his, ques, ans, ans_target, quesL, opt_ans, \\\n",
    "                    opt_ans_target, ans_ids, ans_len, opt_ans_len, img_id\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(epoch):\n",
    "    netW.train()\n",
    "    netE.train()\n",
    "    netD.train()\n",
    "\n",
    "#     lr = adjust_learning_rate(optimizer, epoch, opt.lr)\n",
    "\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "\n",
    "    data_iter = iter(dloader)\n",
    "\n",
    "    average_loss = 0\n",
    "    count = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(dloader):\n",
    "\n",
    "        t1 = time.time()\n",
    "        data = data_iter.next()\n",
    "        \n",
    "        image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answerIds, answerLen, opt_answerLen, img_id  = data\n",
    "            \n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "        print(image.size(),'image size')\n",
    "        print(img_input.size(),'img_input')\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            netW.zero_grad()\n",
    "            netE.zero_grad()\n",
    "            netD.zero_grad()\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            ans = answer[:,rnd,:].t()\n",
    "            tans = answerT[:,rnd,:].t()\n",
    "#             wrong_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "\n",
    "#             real_len = answerLen[:,rnd]\n",
    "#             wrong_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            ans_input.data.resize_(ans.size()).copy_(ans)\n",
    "            ans_target.data.resize_(tans.size()).copy_(tans)\n",
    "#             wrong_ans_input.data.resize_(wrong_ans.size()).copy_(wrong_ans)\n",
    "\n",
    "            # sample in-batch negative index\n",
    "#             batch_sample_idx.data.resize_(batch_size, neg_batch_sample).zero_()\n",
    "#             sample_batch_neg(answerIdx[:,rnd], opt_answerIdx[:,rnd,:], batch_sample_idx, neg_batch_sample)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "            \n",
    "#             print('----------------Encoder:')\n",
    "#             print('ques_emb',ques_emb.size())\n",
    "#             print('his_emb',his_emb.size())\n",
    "#             print('img input size:', img_input.size())\n",
    "            \n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "#             ans_real_emb = netW(ans_target, format='index')\n",
    "#             ans_wrong_emb = netW(wrong_ans_input, format='index')\n",
    "\n",
    "#             real_hidden = repackage_hidden(real_hidden, batch_size)\n",
    "#             wrong_hidden = repackage_hidden(wrong_hidden, ans_wrong_emb.size(1))\n",
    "\n",
    "#             real_feat = netD(ans_real_emb, ans_target, real_hidden, vocab_size)\n",
    "#             wrong_feat = netD(ans_wrong_emb, wrong_ans_input, wrong_hidden, vocab_size)\n",
    "\n",
    "#             batch_wrong_feat = wrong_feat.index_select(0, batch_sample_idx.view(-1))\n",
    "#             wrong_feat = wrong_feat.view(batch_size, -1, ninp)\n",
    "#             batch_wrong_feat = batch_wrong_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "#             nPairLoss = critD(featD, real_feat, wrong_feat, batch_wrong_feat)\n",
    "\n",
    "#             opt_ans = opt_answerT[:,:,rnd,:].clone().view(-1, ans_length).t()\n",
    "#             opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "            \n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "\n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "\n",
    "            opt_hidden = netD.init_hidden(batchSize)\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "#             print('--------------Decoder:')\n",
    "#             print('opt_ans_input',opt_ans_input.size())\n",
    "#             print('featD', featD.size())\n",
    "#             print('opt_ans_emb',opt_ans_emb.size())\n",
    "            \n",
    "            prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "#             optIdx = opt_answerIdx[:,rnd,:]\n",
    "            # print(optIdx.size())\n",
    "            ansIds = answerIds[:,rnd]\n",
    "            ansIds = ansIds.long()\n",
    "            ansIds = Variable(ansIds, requires_grad = False)\n",
    "            \n",
    "            if enCuda:\n",
    "                ansIds = ansIds.cuda()\n",
    "            \n",
    "\n",
    "#             print(ansIds)            \n",
    "            currLoss = critD(prob,ansIds)\n",
    "            print('currLoss:',currLoss[0])\n",
    "#             average_loss += currLoss.data[0]\n",
    "#             print(currLoss.size())\n",
    "#             print(currLoss[0])\n",
    "            currLoss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "\n",
    "        i += 1\n",
    "        if i % log_interval == 0:\n",
    "            average_loss /= count\n",
    "            print(\"step {} / {} (epoch {}), g_loss {:.3f}, lr = {:.6f}\"\\\n",
    "                .format(i, len(dloader), epoch, average_loss, lr))\n",
    "            average_loss = 0\n",
    "            count = 0\n",
    "\n",
    "    return average_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valModel():\n",
    "    netE.eval()\n",
    "    netW.eval()\n",
    "    netD.eval()\n",
    "\n",
    "#     n_neg = 100\n",
    "    data_iter_val = iter(dataloader_val)\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "    i = 0\n",
    "\n",
    "    average_loss = 0\n",
    "    rank_all_tmp = []\n",
    "\n",
    "#     while i < len(dataloader_val):\n",
    "    while i < 10:\n",
    "        data = data_iter_val.next()\n",
    "        image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answer_ids, answerLen, opt_answerLen, img_id  = data\n",
    "\n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "        #image = l2_norm(image)\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            gt_id = answer_ids[:,rnd]\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "            gt_index.data.resize_(gt_id.size()).copy_(gt_id)\n",
    "            opt_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "            \n",
    "#             print('----------------Encoder:')\n",
    "#             print('ques_emb',ques_emb.size())\n",
    "#             print('his_emb',his_emb.size())\n",
    "#             print('img input size:', img_input.size())\n",
    "            \n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "            \n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "            \n",
    "#             print('--------------Decoder:')\n",
    "#             print('opt_ans_input',opt_ans_input.size())\n",
    "#             print('featD', featD.size())\n",
    "#             print('opt_ans_emb',opt_ans_emb.size())\n",
    "            \n",
    "            score = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "            \n",
    "#             opt_feat = opt_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "            #ans_emb = ans_emb.view(ans_length, -1, 100, opt.nhid)\n",
    "#             featD = featD.view(-1, ninp, 1)\n",
    "#             score = torch.bmm(opt_feat, featD)\n",
    "#             score = score.view(-1, 100)\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                gt_index.data[b] = gt_index.data[b] + b*100\n",
    "\n",
    "            gt_score = score.view(-1).index_select(0, gt_index)\n",
    "            sort_score, sort_idx = torch.sort(score, 1, descending=True)\n",
    "\n",
    "            count = sort_score.gt(gt_score.view(-1,1).expand_as(sort_score))\n",
    "            rank = count.sum(1) + 1\n",
    "            rank_all_tmp += list(rank.view(-1).data.cpu().numpy())\n",
    "            \n",
    "        i += 1\n",
    "        sys.stdout.write('Evaluating: {:d}/{:d}  \\r' \\\n",
    "          .format(i, len(dataloader_val)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return rank_all_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class share_Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = Ax + b`\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias. Default: True\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in\\_features)`\n",
    "        - Output: :math:`(N, out\\_features)`\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape (out_features x in_features)\n",
    "        bias:   the learnable bias of the module of shape (out_features)\n",
    "    Examples::\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = autograd.Variable(torch.randn(128, 20))\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight):\n",
    "        super(share_Linear, self).__init__()\n",
    "        self.in_features = weight.size(0)\n",
    "        self.out_features = weight.size(1)\n",
    "        self.weight = weight.t()\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + str(self.in_features) + ' -> ' \\\n",
    "            + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'LSTM'\n",
    "ninp = 300\n",
    "nhid = 512\n",
    "nlayers = 1\n",
    "dropout = 0.5\n",
    "margin = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Here for input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_img_h5 = 'vdl_img_vgg_demo.h5'\n",
    "# input_ques_h5 = 'visdial_data_demo.h5'\n",
    "input_img_h5 = 'vdl_img_vgg.h5'\n",
    "input_ques_h5 = 'visdial_data.h5'\n",
    "input_json = 'visdial_params.json'\n",
    "negative_sample = 20\n",
    "num_val = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: train\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "train number of data: 81783\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "dataset = train(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: test\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "test number of data: 40504\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "dataset_val = validate(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "num_workers = 0\n",
    "dloader = torch.utils.data.DataLoader(dataset_val, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=int(num_workers))\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=1,\n",
    "                                         shuffle=False, num_workers=int(num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_iter1 = iter(dloader)\n",
    "data = data_iter1.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in case dataloader used is dloader\n",
    "# image, history, question, answer, answerT, answerLen, answerIdx, answerIds, questionL, \\\n",
    "#         opt_answerT, opt_answerLen, opt_answerIdx = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answerIds, answerLen, opt_answerLen, img_id  = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wantVal = 0\n",
    "if wantVal == 1:\n",
    "    data_iter_val = iter(dataloader_val)\n",
    "    data_val = data_iter_val.next()\n",
    "    image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answer_ids, answerLen, opt_answerLen, img_id  = data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd = 3\n",
    "ques_length = dataset.ques_length\n",
    "negative_sample = 20\n",
    "n_neg = negative_sample\n",
    "vocab_size = dataset.vocab_size\n",
    "ques_length = dataset.ques_length\n",
    "ans_length = dataset.ans_length + 1\n",
    "his_length = dataset.ans_length + dataset.ques_length\n",
    "itow = dataset.itow\n",
    "img_feat_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netW = _netW(vocab_size, ninp, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netE = _netE(model, ninp, nhid, nlayers, dropout, img_feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    netE.cuda()\n",
    "    netW.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "if enCuda:\n",
    "    ques_input = ques_input.cuda()\n",
    "ques_input = Variable(ques_input)\n",
    "ques = question[:,rnd,:].t()\n",
    "ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "\n",
    "ques_emb = netW(ques_input, format = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = image.view(-1, img_feat_size)\n",
    "img_input = torch.FloatTensor(batchSize)\n",
    "img_input = Variable(img_input)\n",
    "img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "if(enCuda):\n",
    "    his_input = his_input.cuda()\n",
    "his_input = Variable(his_input)\n",
    "his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "batch_size = question.size(0)\n",
    "\n",
    "ques_hidden = netE.init_hidden(batchSize)\n",
    "hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    his_input = his_input.cuda()\n",
    "    ques_input = ques_input.cuda()\n",
    "    img_input = img_input.cuda()\n",
    "    ques_emb = ques_emb.cuda()\n",
    "    his_emb = his_emb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featD, ques_hidden = netE(ques_emb, his_emb, img_input, ques_hidden, hist_hidden, rnd+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "netD = _netD(model, ninp, nhid, nlayers, vocab_size, dropout)\n",
    "if enCuda:\n",
    "    netD.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "if enCuda:\n",
    "    opt_ans_input = opt_ans_input.cuda()\n",
    "\n",
    "opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "\n",
    "\n",
    "opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "# opt_ans_emb = opt_ans_emb.cuda()\n",
    "\n",
    "opt_hidden = netD.init_hidden(batchSize)\n",
    "# opt_hidden.cuda()\n",
    "opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "# opt_hidden[0].data.cuda()\n",
    "# opt_hidden[1].data.cuda()\n",
    "# opt_hidden = torch.LongTensor(opt_hidden)\n",
    "# print(opt_hidden.shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Val Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del img_input, ques_input, his_input, ans_input, ans_target, wrong_ans_input, opt_ans_input, batch_sample_idx\n",
    "# del fake_diff_mask, fake_len, noise_input, gt_index\n",
    "# %reset \n",
    "img_input = torch.FloatTensor(batchSize)\n",
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "\n",
    "# answer input\n",
    "ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "ans_target = torch.LongTensor(ans_length, batchSize)\n",
    "wrong_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "sample_ans_input = torch.LongTensor(1, batchSize)\n",
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "\n",
    "batch_sample_idx = torch.LongTensor(batchSize)\n",
    "fake_diff_mask = torch.ByteTensor(batchSize)\n",
    "fake_len = torch.LongTensor(batchSize)\n",
    "noise_input = torch.FloatTensor(batchSize)\n",
    "gt_index = torch.LongTensor(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    ques_input, his_input, img_input = ques_input.cuda(), his_input.cuda(), img_input.cuda()\n",
    "    ans_input, ans_target = ans_input.cuda(), ans_target.cuda()\n",
    "    wrong_ans_input = wrong_ans_input.cuda()\n",
    "    sample_ans_input = sample_ans_input.cuda()\n",
    "\n",
    "    fake_len = fake_len.cuda()\n",
    "    noise_input = noise_input.cuda()\n",
    "    batch_sample_idx = batch_sample_idx.cuda()\n",
    "    fake_diff_mask = fake_diff_mask.cuda()\n",
    "    opt_ans_input = opt_ans_input.cuda()\n",
    "    gt_index = gt_index.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ques_input = Variable(ques_input)\n",
    "img_input = Variable(img_input)\n",
    "his_input = Variable(his_input)\n",
    "\n",
    "ans_input = Variable(ans_input)\n",
    "ans_target = Variable(ans_target)\n",
    "wrong_ans_input = Variable(wrong_ans_input)\n",
    "sample_ans_input = Variable(sample_ans_input)\n",
    "\n",
    "noise_input = Variable(noise_input)\n",
    "batch_sample_idx = Variable(batch_sample_idx)\n",
    "fake_diff_mask = Variable(fake_diff_mask)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "gt_index = Variable(gt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 0.0004\n",
    "beta1 = 0.8\n",
    "log_interval = 50\n",
    "optimizer = optim.Adam([{'params': netW.parameters()},\n",
    "                        {'params': netE.parameters()},\n",
    "                        {'params': netD.parameters()}], lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([490, 512]), 'image size')\n",
      "(torch.Size([10]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: mismatch between the batch size of input (100) and that of target (10) at /opt/conda/conda-bld/pytorch_1518238581238/work/torch/lib/THCUNN/generic/ClassNLLCriterion.cu:39",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-74f91eb5c1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-d9d53609dd34>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m#             print(ansIds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mcurrLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mansIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'currLoss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrLoss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m#             average_loss += currLoss.data[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/loss.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         return F.nll_loss(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 170\u001b[0;31m                           self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: mismatch between the batch size of input (100) and that of target (10) at /opt/conda/conda-bld/pytorch_1518238581238/work/torch/lib/THCUNN/generic/ClassNLLCriterion.cu:39"
     ]
    }
   ],
   "source": [
    "critD = nn.NLLLoss()\n",
    "\n",
    "if enCuda:\n",
    "    critD.cuda()\n",
    "\n",
    "# netW.cuda()\n",
    "epoch = 0\n",
    "\n",
    "trainModel(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "1/40504: mrr: 1.000000 R1: 1.000000 R5 1.000000 R10 1.000000 Mean 1.000000\n"
     ]
    }
   ],
   "source": [
    "rank_all = valModel()\n",
    "epoch = 1\n",
    "R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ebf257d4464a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;34m'netD'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     'netE': netE.state_dict()},\n\u001b[0;32m----> 6\u001b[0;31m                     '%s/epoch_%d.pth' % (save_path, epoch))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_path' is not defined"
     ]
    }
   ],
   "source": [
    "# save_path = '~/notebooks/save'\n",
    "torch.save({'epoch': epoch,\n",
    "                    'netW': netW.state_dict(),\n",
    "                    'netD': netD.state_dict(),\n",
    "                    'netE': netE.state_dict()},\n",
    "                    '%s/epoch_%d.pth' % (save_path, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_path = ''\n",
    "# model_path = save_path\n",
    "model_path = './save/D.15-4-16/epoch_1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './save/D.15-4-16/epoch_1.pth'\n"
     ]
    }
   ],
   "source": [
    "outf = './save'\n",
    "decoder = 'D'\n",
    "\n",
    "if model_path != '':\n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    batchSize = 1\n",
    "else:\n",
    "    # create new folder.\n",
    "    t = datetime.datetime.now()\n",
    "    cur_time = '%s-%s-%s' %(t.day, t.month, t.hour)\n",
    "    save_path = os.path.join(outf, decoder + '.' + cur_time)\n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_path != '': # load the pre-trained model.\n",
    "    netW.load_state_dict(checkpoint['netW'])\n",
    "    netE.load_state_dict(checkpoint['netE'])\n",
    "    netD.load_state_dict(checkpoint['netD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3675\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6250\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5741\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.8635\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7486\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.8231\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7041\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6083\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6193\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6002\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4547\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5883\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6464\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4856\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4131\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4859\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5881\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5694\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6071\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3963\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4763\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6822\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4983\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4574\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5809\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7475\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5244\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6014\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6559\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6014\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5326\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7337\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7925\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7023\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7938\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5994\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.8498\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4785\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6632\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4818\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5042\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6341\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5562\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6659\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5606\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6654\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6154\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5496\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6267\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6042\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3027\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6916\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7226\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6149\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5835\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5929\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7042\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5449\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5938\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4604\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4017\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4303\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7177\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5250\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6559\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4019\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5210\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5477\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4385\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4424\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3349\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7419\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7811\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7259\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5633\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5090\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6712\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6343\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6941\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4123\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4930\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5264\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6241\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7268\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6313\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6985\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4601\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6831\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5115\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5344\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5008\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6429\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5435\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5602\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4798\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7518\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5083\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4915\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5489\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3431\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4513\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7805\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7220\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6799\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6448\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6185\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6497\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5713\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4079\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5197\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3579\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6325\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6981\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5988\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5845\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6789\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6885\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4764\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6391\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3968\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3398\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6152\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5133\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6125\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5102\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6065\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3637\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4250\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4371\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4840\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.2743\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5232\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5056\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5752\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7050\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6043\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5561\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.2018\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6450\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.2428\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5132\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7421\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5384\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7440\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6909\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5716\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4338\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4761\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6250\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5361\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4808\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6132\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6814\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4682\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5897\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3987\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6277\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.3749\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4926\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.2605\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.0500\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.8066\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5769\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.8264\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6366\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5293\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6522\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.6289\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7153\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7741\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4059\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.5032\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4233\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.4602\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('currLoss:', Variable containing:\n",
      " 3.7208\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0004\n",
    "beta1 = 0.8\n",
    "niter = 5\n",
    "neg_batch_sample = 30 \n",
    "log_interval = 50\n",
    "save_iter = 1\n",
    "save_path = '~/notebooks/saved_checkpoints'\n",
    "optimizer = optim.Adam([{'params': netW.parameters()},\n",
    "                        {'params': netE.parameters()},\n",
    "                        {'params': netD.parameters()}], lr=lr, betas=(beta1, 0.999))\n",
    "enCuda = 1\n",
    "\n",
    "if enCuda:\n",
    "    torch.cuda.manual_seed(manualSeed)\n",
    "    \n",
    "critD = nn.NLLLoss()\n",
    "if enCuda:\n",
    "    critD.cuda()\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(niter):\n",
    "    t = time.time()\n",
    "    train_loss = trainModel(epoch)\n",
    "    print ('Epoch: %d learningRate %4f train loss %4f Time: %3f' % (epoch, lr, train_loss, time.time()-t))\n",
    "    train_his = {'loss': train_loss}\n",
    "\n",
    "    print('Evaluating ... ')\n",
    "    rank_all = valModel()\n",
    "    R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "    R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "    R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "    ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "    mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "    print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))\n",
    "    val_his = {'R1': R1, 'R5':R5, 'R10': R10, 'Mean':ave, 'mrr':mrr}\n",
    "    history.append({'epoch':epoch, 'train': train_his, 'val': val_his})\n",
    "\n",
    "#     saving the model.\n",
    "    if epoch % save_iter == 0:\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'netW': netW.state_dict(),\n",
    "                    'netD': netD.state_dict(),\n",
    "                    'netE': netE.state_dict()},\n",
    "                    '%s/epoch_%d.pth' % (save_path, epoch))\n",
    "\n",
    "        json.dump(history, open('%s/log.json' %(save_path), 'w'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
