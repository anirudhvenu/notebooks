{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import time\n",
    "import pdb\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#             print(ansIdx.size())\n",
    "#             b_no = 0\n",
    "#             ans_list = []\n",
    "            \n",
    "#             for elem in ansIdx:\n",
    "#                 t = ((optIdx[b_no,:]==elem).nonzero())\n",
    "#             #     print(t.size())\n",
    "#                 if (t.size()!=torch.Size([])):\n",
    "#                     ans_list.append(t[0][0])\n",
    "#                 else:\n",
    "#                     ans_list.append((-1))\n",
    "    \n",
    "#                 b_no = b_no + 1\n",
    "\n",
    "#             corr_ans_ind = torch.LongTensor(ans_list)\n",
    "            \n",
    "\n",
    "#             corr_ans_ind = Variable(corr_ans_ind)\n",
    "#             corr_ans_ind = corr_ans_ind.cuda()\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Seed: ', 1498)\n"
     ]
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000) # fix seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enCuda = 1\n",
    "if enCuda:\n",
    "    torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netE(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, dropout, img_feat_size):\n",
    "        super(_netE, self).__init__()\n",
    "\n",
    "        self.d = dropout\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.nhid = nhid\n",
    "        self.ninp = ninp\n",
    "        self.img_feat_size = img_feat_size\n",
    "\n",
    "        self.img_embed = nn.Linear(img_feat_size, nhid)\n",
    "        self.ques_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "        self.his_rnn = nn.LSTM(self.ninp, self.nhid, self.nlayers)\n",
    "\n",
    "        self.Wq_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wh_1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.Wi_1 = nn.Linear(self.img_feat_size, self.nhid)\n",
    "        self.Wa_1 = nn.Linear(self.nhid, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.nhid*3, self.ninp)\n",
    "\n",
    "    def forward(self, ques_emb, his_emb, img_raw, ques_hidden, his_hidden, rnd):\n",
    "\n",
    "        img_emb = F.tanh(self.img_embed(img_raw))\n",
    "        ques_feat, ques_hidden = self.ques_rnn(ques_emb, ques_hidden)\n",
    "        ques_feat = ques_feat[-1]\n",
    "        his_feat, his_hidden = self.his_rnn(his_emb, his_hidden)\n",
    "        his_feat = his_feat[-1]\n",
    "\n",
    "        ques_emb_1 = self.Wq_1(ques_feat).view(-1, 1, self.nhid)\n",
    "        his_emb_1 = self.Wh_1(his_feat).view(-1, rnd, self.nhid)\n",
    "        his_cat = his_emb_1.mean(1)\n",
    "\n",
    "        img_cat = img_emb.view(-1,49,self.nhid)\n",
    "        img_cat = img_cat.mean(1)\n",
    "        \n",
    "        concat_feat = torch.cat((ques_feat, his_cat.view(-1, self.nhid), \\\n",
    "                                 img_cat.view(-1, self.nhid)),1)\n",
    "        \n",
    "        encoder_feat = F.tanh(self.fc1(F.dropout(concat_feat, self.d, training=self.training)))\n",
    "\n",
    "        return encoder_feat, ques_hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####CHANGE CUDA\n",
    "\n",
    "class _netW(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, dropout):\n",
    "        super(_netW, self).__init__()\n",
    "        self.word_embed = nn.Embedding(ntoken+1, ninp)\n",
    "        self.Linear = share_Linear(self.word_embed.weight)\n",
    "        \n",
    "        if enCuda:\n",
    "            self.word_embed = nn.Embedding(ntoken+1, ninp).cuda()\n",
    "            self.Linear = share_Linear(self.word_embed.weight).cuda()\n",
    "\n",
    "        self.init_weights()\n",
    "        self.d = dropout\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.word_embed.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, format ='index'):\n",
    "        if format == 'onehot':\n",
    "            out = F.dropout(self.Linear(input), self.d, training=self.training)\n",
    "        elif format == 'index':\n",
    "            out = F.dropout(self.word_embed(input), self.d, training=self.training)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    \"\"\"\n",
    "    Given the real/wrong/fake answer, use a RNN (LSTM) to embed the answer.\n",
    "    \"\"\"\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, ntoken, dropout):\n",
    "        super(_netD, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.ntoken = ntoken\n",
    "        self.ninp = ninp\n",
    "        self.d = dropout\n",
    "\n",
    "        self.ans_rnn = nn.LSTM(self.ninp, self.ninp, self.nlayers)\n",
    "        self.W2 = nn.Linear(self.nhid, 1)\n",
    "        self.fc = nn.Linear(nhid, ninp)\n",
    "\n",
    "    def forward(self, input_feat, hidden, opt_ans_emb, vocab_size):\n",
    "\n",
    "        # opt_ans_emb = self.ans_emb(opt_ans.view(-1,200,9))\n",
    "        print(type(hidden[0]))\n",
    "        output, h = self.ans_rnn(opt_ans_emb, hidden)\n",
    "        output = output[-1]\n",
    "#         output = output.view(100,-1,self.ninp)        \n",
    "        # redOutput = output.mean(1).view(100,self.ninp,-1)\n",
    "        output_feat = output.view(-1,100,self.ninp)\n",
    "        expand_feat = input_feat.view(-1,self.ninp,1)\n",
    "\n",
    "        print('-------------Within Decoder:')\n",
    "        print('expand feat', expand_feat.size())\n",
    "        print('output_feat',output_feat.size())\n",
    "        \n",
    "#         feat = output_feat.view(-1,100,1,self.ninp)\n",
    "#         expand_feat = expand_feat.expand(feat.size())\n",
    "#         expand_feat = expand_feat.view(-1,1,self.ninp)\n",
    "        \n",
    "        prob = F.log_softmax(torch.bmm(output_feat,expand_feat)).view(100,-1)\n",
    "\n",
    "        return prob\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            if enCuda:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()).cuda(),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()).cuda())\n",
    "            else:\n",
    "                return (Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()),\n",
    "                        Variable(weight.new(self.nlayers, bsz, self.ninp).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers, bsz, self.ninp).zero_())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h, batch_size):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data.resize_(h.size(0), batch_size, h.size(2)).zero_())\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v, batch_size) for v in h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class train(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "            \n",
    "        self.img_info = self.img_info[s:e]\n",
    "\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # get the image\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ques_ori = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, self.negative_sample, self.ans_length+1))\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, self.negative_sample))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        ans_idx = np.zeros((self.rnd))\n",
    "        opt_ans_idx = np.zeros((self.rnd, self.negative_sample))\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                his[i+1, self.his_length-qa_len:self.his_length-a_len] = self.ques[index, i, :q_len]\n",
    "                his[i+1, self.his_length-a_len:] = self.ans[index, i, :a_len]\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "\n",
    "            ques_ori[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            # random select the negative samples.\n",
    "            ans_idx[i] = opt_ids[self.ans_ids[index, i]]\n",
    "            # exclude the gt index.\n",
    "            opt_ids = np.delete(opt_ids, ans_idx[i], 0)\n",
    "            random.shuffle(opt_ids)\n",
    "            for j in range(self.negative_sample):\n",
    "                ids = opt_ids[j]\n",
    "                opt_ans_idx[i,j] = ids\n",
    "\n",
    "                opt_len = self.opt_len[ids]\n",
    "                \n",
    "                opt_ans_len[i, j] = opt_len\n",
    "                \n",
    "                opt_ans[i, j, 1:opt_len+1] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, 0] = self.vocab_size\n",
    "                \n",
    "#                 opt_ans[i, j, :opt_len] = self.opt_list[ids,:opt_len]\n",
    "#                 opt_ans[i, j, opt_len] = self.vocab_size\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        ques_ori = torch.from_numpy(ques_ori)\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        ans_idx = torch.from_numpy(ans_idx)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "        opt_ans_idx = torch.from_numpy(opt_ans_idx)\n",
    "        return img, his, ques, ans, ans_target, ans_len, ans_idx, ans_ids, ques_ori, \\\n",
    "                opt_ans, opt_ans_len, opt_ans_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class validate(data.Dataset): # torch wrapper\n",
    "    def __init__(self, input_img_h5, input_ques_h5, input_json, negative_sample, num_val, data_split):\n",
    "\n",
    "        print('DataLoader loading: %s' %data_split)\n",
    "        print('Loading image feature from %s' %input_img_h5)\n",
    "\n",
    "        if data_split == 'test':\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'train' # train and val split both corresponding to 'train'\n",
    "\n",
    "        f = json.load(open(input_json, 'r'))\n",
    "        self.itow = f['itow']\n",
    "        self.img_info = f['img_'+split]\n",
    "\n",
    "        # get the data split.\n",
    "        total_num = len(self.img_info)\n",
    "        if data_split == 'train':\n",
    "            s = 0\n",
    "            e = total_num - num_val\n",
    "        elif data_split == 'val':\n",
    "            s = total_num - num_val\n",
    "            e = total_num\n",
    "        else:\n",
    "            s = 0\n",
    "            e = total_num\n",
    "\n",
    "        self.img_info = self.img_info[s:e]\n",
    "        print('%s number of data: %d' %(data_split, e-s))\n",
    "\n",
    "        # load the data.\n",
    "        f = h5py.File(input_img_h5, 'r')\n",
    "###########################################################################################\n",
    "#CHANGE THIS HERE FOR NON DEMO TRAINING SET\n",
    "        split = 'train'\n",
    "###########################################################################################\n",
    "        \n",
    "        self.imgs = f['images_'+split][s:e]\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        print('Loading txt from %s' %input_ques_h5)\n",
    "        f = h5py.File(input_ques_h5, 'r')\n",
    "        self.ques = f['ques_'+split][s:e]\n",
    "        self.ans = f['ans_'+split][s:e]\n",
    "        self.cap = f['cap_'+split][s:e]\n",
    "\n",
    "        self.ques_len = f['ques_len_'+split][s:e]\n",
    "        self.ans_len = f['ans_len_'+split][s:e]\n",
    "        self.cap_len = f['cap_len_'+split][s:e]\n",
    "\n",
    "        self.ans_ids = f['ans_index_'+split][s:e]\n",
    "        self.opt_ids = f['opt_'+split][s:e]\n",
    "        self.opt_list = f['opt_list_'+split][:]\n",
    "        self.opt_len = f['opt_len_'+split][:]\n",
    "        f.close()\n",
    "\n",
    "        self.ques_length = self.ques.shape[2]\n",
    "        self.ans_length = self.ans.shape[2]\n",
    "        self.his_length = self.ques_length + self.ans_length\n",
    "        self.vocab_size = len(self.itow)+1\n",
    "\n",
    "        print('Vocab Size: %d' % self.vocab_size)\n",
    "        self.split = split\n",
    "        self.rnd = 10\n",
    "        self.negative_sample = negative_sample\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # get the image\n",
    "        img_id = self.img_info[index]['imgId']\n",
    "        img = torch.from_numpy(self.imgs[index])\n",
    "        # get the history\n",
    "        his = np.zeros((self.rnd, self.his_length))\n",
    "        his[0,self.his_length-self.cap_len[index]:] = self.cap[index,:self.cap_len[index]]\n",
    "\n",
    "        ques = np.zeros((self.rnd, self.ques_length))\n",
    "        ans = np.zeros((self.rnd, self.ans_length+1))\n",
    "        ans_target = np.zeros((self.rnd, self.ans_length+1))\n",
    "        quesL = np.zeros((self.rnd, self.ques_length))\n",
    "\n",
    "        opt_ans = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "        ans_ids = np.zeros(self.rnd)\n",
    "        opt_ans_target = np.zeros((self.rnd, 100, self.ans_length+1))\n",
    "\n",
    "        ans_len = np.zeros((self.rnd))\n",
    "        opt_ans_len = np.zeros((self.rnd, 100))\n",
    "\n",
    "\n",
    "        for i in range(self.rnd):\n",
    "            # get the index\n",
    "            q_len = self.ques_len[index, i]\n",
    "            a_len = self.ans_len[index, i]\n",
    "            qa_len = q_len + a_len\n",
    "\n",
    "            if i+1 < self.rnd:\n",
    "                ques_ans = np.concatenate([self.ques[index, i, :q_len], self.ans[index, i, :a_len]])\n",
    "                his[i+1, self.his_length-qa_len:] = ques_ans\n",
    "\n",
    "            ques[i, self.ques_length-q_len:] = self.ques[index, i, :q_len]\n",
    "            quesL[i, :q_len] = self.ques[index, i, :q_len]\n",
    "            ans[i, 1:a_len+1] = self.ans[index, i, :a_len]\n",
    "            ans[i, 0] = self.vocab_size\n",
    "\n",
    "            ans_target[i, :a_len] = self.ans[index, i, :a_len]\n",
    "            ans_target[i, a_len] = self.vocab_size\n",
    "\n",
    "            ans_ids[i] = self.ans_ids[index, i] # since python start from 0\n",
    "            opt_ids = self.opt_ids[index, i] # since python start from 0\n",
    "            ans_len[i] = self.ans_len[index, i]\n",
    "            ans_idx = self.ans_ids[index, i]\n",
    "\n",
    "            for j, ids in enumerate(opt_ids):\n",
    "                opt_len = self.opt_len[ids]\n",
    "                opt_ans[i, j, 1:opt_len+1] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans[i, j, 0] = self.vocab_size\n",
    "\n",
    "                opt_ans_target[i, j,:opt_len] = self.opt_list[ids,:opt_len]\n",
    "                opt_ans_target[i, j,opt_len] = self.vocab_size\n",
    "                opt_ans_len[i, j] = opt_len\n",
    "\n",
    "        opt_ans = torch.from_numpy(opt_ans)\n",
    "        opt_ans_target = torch.from_numpy(opt_ans_target)\n",
    "        ans_ids = torch.from_numpy(ans_ids)\n",
    "\n",
    "        his = torch.from_numpy(his)\n",
    "        ques = torch.from_numpy(ques)\n",
    "        ans = torch.from_numpy(ans)\n",
    "        ans_target = torch.from_numpy(ans_target)\n",
    "        quesL = torch.from_numpy(quesL)\n",
    "\n",
    "        ans_len = torch.from_numpy(ans_len)\n",
    "        opt_ans_len = torch.from_numpy(opt_ans_len)\n",
    "\n",
    "        return img, his, ques, ans, ans_target, quesL, opt_ans, \\\n",
    "                    opt_ans_target, ans_ids, ans_len, opt_ans_len, img_id\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ques.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(epoch):\n",
    "    netW.train()\n",
    "    netE.train()\n",
    "    netD.train()\n",
    "\n",
    "#     lr = adjust_learning_rate(optimizer, epoch, opt.lr)\n",
    "\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "\n",
    "    data_iter = iter(dloader)\n",
    "\n",
    "    average_loss = 0\n",
    "    count = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(dloader):\n",
    "\n",
    "        t1 = time.time()\n",
    "        data = data_iter.next()\n",
    "        \n",
    "        image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answerIds, answerLen, opt_answerLen, img_id  = data\n",
    "            \n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "        print(image.size(),'image size')\n",
    "        print(img_input.size(),'img_input')\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            netW.zero_grad()\n",
    "            netE.zero_grad()\n",
    "            netD.zero_grad()\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            ans = answer[:,rnd,:].t()\n",
    "            tans = answerT[:,rnd,:].t()\n",
    "#             wrong_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "\n",
    "#             real_len = answerLen[:,rnd]\n",
    "#             wrong_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            ans_input.data.resize_(ans.size()).copy_(ans)\n",
    "            ans_target.data.resize_(tans.size()).copy_(tans)\n",
    "#             wrong_ans_input.data.resize_(wrong_ans.size()).copy_(wrong_ans)\n",
    "\n",
    "            # sample in-batch negative index\n",
    "#             batch_sample_idx.data.resize_(batch_size, neg_batch_sample).zero_()\n",
    "#             sample_batch_neg(answerIdx[:,rnd], opt_answerIdx[:,rnd,:], batch_sample_idx, neg_batch_sample)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "            \n",
    "            print('----------------Encoder:')\n",
    "            print('ques_emb',ques_emb.size())\n",
    "            print('his_emb',his_emb.size())\n",
    "            print('img input size:', img_input.size())\n",
    "            \n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "#             ans_real_emb = netW(ans_target, format='index')\n",
    "#             ans_wrong_emb = netW(wrong_ans_input, format='index')\n",
    "\n",
    "#             real_hidden = repackage_hidden(real_hidden, batch_size)\n",
    "#             wrong_hidden = repackage_hidden(wrong_hidden, ans_wrong_emb.size(1))\n",
    "\n",
    "#             real_feat = netD(ans_real_emb, ans_target, real_hidden, vocab_size)\n",
    "#             wrong_feat = netD(ans_wrong_emb, wrong_ans_input, wrong_hidden, vocab_size)\n",
    "\n",
    "#             batch_wrong_feat = wrong_feat.index_select(0, batch_sample_idx.view(-1))\n",
    "#             wrong_feat = wrong_feat.view(batch_size, -1, ninp)\n",
    "#             batch_wrong_feat = batch_wrong_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "#             nPairLoss = critD(featD, real_feat, wrong_feat, batch_wrong_feat)\n",
    "\n",
    "#             opt_ans = opt_answerT[:,:,rnd,:].clone().view(-1, ans_length).t()\n",
    "#             opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "            \n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "\n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "\n",
    "            opt_hidden = netD.init_hidden(batchSize)\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "            print('--------------Decoder:')\n",
    "            print('opt_ans_input',opt_ans_input.size())\n",
    "            print('featD', featD.size())\n",
    "            print('opt_ans_emb',opt_ans_emb.size())\n",
    "            \n",
    "            prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "#             optIdx = opt_answerIdx[:,rnd,:]\n",
    "            # print(optIdx.size())\n",
    "            ansIds = answerIds[:,rnd]\n",
    "            ansIds = ansIds.long()\n",
    "            ansIds = Variable(ansIds, requires_grad = False)\n",
    "            \n",
    "            if enCuda:\n",
    "                ansIds = ansIds.cuda()\n",
    "            \n",
    "\n",
    "#             print(ansIds)            \n",
    "            currLoss = critD(prob,ansIds)\n",
    "#             print('currLoss:',curr.size())\n",
    "#             average_loss += currLoss.data[0]\n",
    "#             print(currLoss.size())\n",
    "#             print(currLoss[0])\n",
    "            currLoss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "\n",
    "        i += 1\n",
    "        if i % log_interval == 0:\n",
    "            average_loss /= count\n",
    "            print(\"step {} / {} (epoch {}), g_loss {:.3f}, lr = {:.6f}\"\\\n",
    "                .format(i, len(dataloader), epoch, average_loss, lr))\n",
    "            average_loss = 0\n",
    "            count = 0\n",
    "\n",
    "    return average_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valModel():\n",
    "    netE.eval()\n",
    "    netW.eval()\n",
    "    netD.eval()\n",
    "\n",
    "#     n_neg = 100\n",
    "    data_iter_val = iter(dataloader_val)\n",
    "    ques_hidden = netE.init_hidden(batchSize)\n",
    "    hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "    opt_hidden = netD.init_hidden(batchSize)\n",
    "    i = 0\n",
    "\n",
    "    average_loss = 0\n",
    "    rank_all_tmp = []\n",
    "\n",
    "#     while i < len(dataloader_val):\n",
    "    while i < 100:\n",
    "        data = data_iter_val.next()\n",
    "        image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answer_ids, answerLen, opt_answerLen, img_id  = data\n",
    "\n",
    "        batch_size = question.size(0)\n",
    "        image = image.view(-1, img_feat_size)\n",
    "        #image = l2_norm(image)\n",
    "        img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "        for rnd in range(10):\n",
    "            # get the corresponding round QA and history.\n",
    "            ques = question[:,rnd,:].t()\n",
    "            his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "\n",
    "            opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "            gt_id = answer_ids[:,rnd]\n",
    "\n",
    "            ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "            his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "            opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "            gt_index.data.resize_(gt_id.size()).copy_(gt_id)\n",
    "            opt_len = opt_answerLen[:,rnd,:].clone().view(-1)\n",
    "\n",
    "            ques_emb = netW(ques_input, format = 'index')\n",
    "            his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "            ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "            hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))\n",
    "            \n",
    "            print('----------------Encoder:')\n",
    "            print('ques_emb',ques_emb.size())\n",
    "            print('his_emb',his_emb.size())\n",
    "            print('img input size:', img_input.size())\n",
    "            \n",
    "            featD, ques_hidden = netE(ques_emb, his_emb, img_input, \\\n",
    "                                                ques_hidden, hist_hidden, rnd+1)\n",
    "\n",
    "            \n",
    "            opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "            opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "            \n",
    "            print('--------------Decoder:')\n",
    "            print('opt_ans_input',opt_ans_input.size())\n",
    "            print('featD', featD.size())\n",
    "            print('opt_ans_emb',opt_ans_emb.size())\n",
    "            \n",
    "            score = netD(featD,opt_hidden,opt_ans_emb,vocab_size)\n",
    "            \n",
    "#             opt_feat = opt_feat.view(batch_size, -1, ninp)\n",
    "\n",
    "            #ans_emb = ans_emb.view(ans_length, -1, 100, opt.nhid)\n",
    "#             featD = featD.view(-1, ninp, 1)\n",
    "#             score = torch.bmm(opt_feat, featD)\n",
    "#             score = score.view(-1, 100)\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                gt_index.data[b] = gt_index.data[b] + b*100\n",
    "\n",
    "            gt_score = score.view(-1).index_select(0, gt_index)\n",
    "            sort_score, sort_idx = torch.sort(score, 1, descending=True)\n",
    "\n",
    "            count = sort_score.gt(gt_score.view(-1,1).expand_as(sort_score))\n",
    "            rank = count.sum(1) + 1\n",
    "            rank_all_tmp += list(rank.view(-1).data.cpu().numpy())\n",
    "            \n",
    "        i += 1\n",
    "        sys.stdout.write('Evaluating: {:d}/{:d}  \\r' \\\n",
    "          .format(i, len(dataloader_val)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return rank_all_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class share_Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = Ax + b`\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias. Default: True\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in\\_features)`\n",
    "        - Output: :math:`(N, out\\_features)`\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape (out_features x in_features)\n",
    "        bias:   the learnable bias of the module of shape (out_features)\n",
    "    Examples::\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = autograd.Variable(torch.randn(128, 20))\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight):\n",
    "        super(share_Linear, self).__init__()\n",
    "        self.in_features = weight.size(0)\n",
    "        self.out_features = weight.size(1)\n",
    "        self.weight = weight.t()\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + str(self.in_features) + ' -> ' \\\n",
    "            + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'LSTM'\n",
    "ninp = 300\n",
    "nhid = 512\n",
    "nlayers = 1\n",
    "dropout = 0.5\n",
    "margin = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Here for input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_img_h5 = 'vdl_img_vgg_demo.h5'\n",
    "# input_ques_h5 = 'visdial_data_demo.h5'\n",
    "input_img_h5 = 'vdl_img_vgg.h5'\n",
    "input_ques_h5 = 'visdial_data.h5'\n",
    "input_json = 'visdial_params.json'\n",
    "negative_sample = 20\n",
    "num_val = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: train\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "train number of data: 81783\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "dataset = train(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading: test\n",
      "Loading image feature from vdl_img_vgg.h5\n",
      "test number of data: 40504\n",
      "Loading txt from visdial_data.h5\n",
      "Vocab Size: 8964\n"
     ]
    }
   ],
   "source": [
    "dataset_val = validate(input_img_h5=input_img_h5, input_ques_h5=input_ques_h5,\n",
    "                input_json=input_json, negative_sample = negative_sample,\n",
    "                num_val = num_val, data_split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "num_workers = 0\n",
    "dloader = torch.utils.data.DataLoader(dataset_val, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=int(num_workers))\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=1,\n",
    "                                         shuffle=False, num_workers=int(num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n",
      "40504\n"
     ]
    }
   ],
   "source": [
    "print(len(dloader))\n",
    "print(len(dataloader_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_iter1 = iter(dloader)\n",
    "data = data_iter1.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in case dataloader used is dloader\n",
    "# image, history, question, answer, answerT, answerLen, answerIdx, answerIds, questionL, \\\n",
    "#         opt_answerT, opt_answerLen, opt_answerIdx = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answerIds, answerLen, opt_answerLen, img_id  = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_answerT.size()\n",
    "answerIds.size()\n",
    "# opt_answerLen.size()\n",
    "# image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wantVal = 0\n",
    "if wantVal == 1:\n",
    "    data_iter_val = iter(dataloader_val)\n",
    "    data_val = data_iter_val.next()\n",
    "    image, history, question, answer, answerT, questionL, opt_answer, \\\n",
    "                opt_answerT, answer_ids, answerLen, opt_answerLen, img_id  = data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 100, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_answerT.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd = 3\n",
    "ques_length = dataset.ques_length\n",
    "negative_sample = 20\n",
    "n_neg = negative_sample\n",
    "vocab_size = dataset.vocab_size\n",
    "ques_length = dataset.ques_length\n",
    "ans_length = dataset.ans_length + 1\n",
    "his_length = dataset.ans_length + dataset.ques_length\n",
    "itow = dataset.itow\n",
    "img_feat_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netW = _netW(vocab_size, ninp, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netE = _netE(model, ninp, nhid, nlayers, dropout, img_feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    netE.cuda()\n",
    "    netW.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "if enCuda:\n",
    "    ques_input = ques_input.cuda()\n",
    "ques_input = Variable(ques_input)\n",
    "ques = question[:,rnd,:].t()\n",
    "ques_input.data.resize_(ques.size()).copy_(ques)\n",
    "\n",
    "ques_emb = netW(ques_input, format = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = image.view(-1, img_feat_size)\n",
    "img_input = torch.FloatTensor(batchSize)\n",
    "img_input = Variable(img_input)\n",
    "img_input.data.resize_(image.size()).copy_(image)\n",
    "\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "if(enCuda):\n",
    "    his_input = his_input.cuda()\n",
    "his_input = Variable(his_input)\n",
    "his = history[:,:rnd+1,:].clone().view(-1, his_length).t()\n",
    "his_input.data.resize_(his.size()).copy_(his)\n",
    "\n",
    "his_emb = netW(his_input, format = 'index')\n",
    "\n",
    "batch_size = question.size(0)\n",
    "\n",
    "ques_hidden = netE.init_hidden(batchSize)\n",
    "hist_hidden = netE.init_hidden(batchSize)\n",
    "\n",
    "ques_hidden = repackage_hidden(ques_hidden, batch_size)\n",
    "hist_hidden = repackage_hidden(hist_hidden, his_input.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    his_input = his_input.cuda()\n",
    "    ques_input = ques_input.cuda()\n",
    "    img_input = img_input.cuda()\n",
    "    ques_emb = ques_emb.cuda()\n",
    "    his_emb = his_emb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 400, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n"
     ]
    }
   ],
   "source": [
    "print('ques_emb',ques_emb.size())\n",
    "print('his_emb',his_emb.size())\n",
    "print('img input size:', img_input.size())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featD, ques_hidden = netE(ques_emb, his_emb, img_input, ques_hidden, hist_hidden, rnd+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "netD = _netD(model, ninp, nhid, nlayers, vocab_size, dropout)\n",
    "if enCuda:\n",
    "    netD.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "if enCuda:\n",
    "    opt_ans_input = opt_ans_input.cuda()\n",
    "\n",
    "opt_ans = opt_answerT[:,rnd,:].clone().view(-1, ans_length).t()\n",
    "opt_ans_input.data.resize_(opt_ans.size()).copy_(opt_ans)\n",
    "\n",
    "\n",
    "opt_ans_emb = netW(opt_ans_input, format = 'index')\n",
    "# opt_ans_emb = opt_ans_emb.cuda()\n",
    "\n",
    "opt_hidden = netD.init_hidden(batchSize)\n",
    "# opt_hidden.cuda()\n",
    "opt_hidden = repackage_hidden(opt_hidden, opt_ans_input.size(1))\n",
    "# opt_hidden[0].data.cuda()\n",
    "# opt_hidden[1].data.cuda()\n",
    "# opt_hidden = torch.LongTensor(opt_hidden)\n",
    "# print(opt_hidden.shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n"
     ]
    }
   ],
   "source": [
    "print('opt_ans_input',opt_ans_input.size())\n",
    "print('featD', featD.size())\n",
    "print('opt_ans_emb',opt_ans_emb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 1, 300])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.randn(100,1,300)\n",
    "o = torch.randn(10000,300,1)\n",
    "\n",
    "t = o.view(-1,100,1,ninp)\n",
    "ans = e.expand(t.size())\n",
    "ans.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "prob = netD(featD,opt_hidden,opt_ans_emb,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Val Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del img_input, ques_input, his_input, ans_input, ans_target, wrong_ans_input, opt_ans_input, batch_sample_idx\n",
    "# del fake_diff_mask, fake_len, noise_input, gt_index\n",
    "# %reset \n",
    "img_input = torch.FloatTensor(batchSize)\n",
    "ques_input = torch.LongTensor(ques_length, batchSize)\n",
    "his_input = torch.LongTensor(his_length, batchSize)\n",
    "\n",
    "# answer input\n",
    "ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "ans_target = torch.LongTensor(ans_length, batchSize)\n",
    "wrong_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "sample_ans_input = torch.LongTensor(1, batchSize)\n",
    "opt_ans_input = torch.LongTensor(ans_length, batchSize)\n",
    "\n",
    "batch_sample_idx = torch.LongTensor(batchSize)\n",
    "fake_diff_mask = torch.ByteTensor(batchSize)\n",
    "fake_len = torch.LongTensor(batchSize)\n",
    "noise_input = torch.FloatTensor(batchSize)\n",
    "gt_index = torch.LongTensor(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if enCuda:\n",
    "    ques_input, his_input, img_input = ques_input.cuda(), his_input.cuda(), img_input.cuda()\n",
    "    ans_input, ans_target = ans_input.cuda(), ans_target.cuda()\n",
    "    wrong_ans_input = wrong_ans_input.cuda()\n",
    "    sample_ans_input = sample_ans_input.cuda()\n",
    "\n",
    "    fake_len = fake_len.cuda()\n",
    "    noise_input = noise_input.cuda()\n",
    "    batch_sample_idx = batch_sample_idx.cuda()\n",
    "    fake_diff_mask = fake_diff_mask.cuda()\n",
    "    opt_ans_input = opt_ans_input.cuda()\n",
    "    gt_index = gt_index.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ques_input = Variable(ques_input)\n",
    "img_input = Variable(img_input)\n",
    "his_input = Variable(his_input)\n",
    "\n",
    "ans_input = Variable(ans_input)\n",
    "ans_target = Variable(ans_target)\n",
    "wrong_ans_input = Variable(wrong_ans_input)\n",
    "sample_ans_input = Variable(sample_ans_input)\n",
    "\n",
    "noise_input = Variable(noise_input)\n",
    "batch_sample_idx = Variable(batch_sample_idx)\n",
    "fake_diff_mask = Variable(fake_diff_mask)\n",
    "opt_ans_input = Variable(opt_ans_input)\n",
    "gt_index = Variable(gt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 0.0004\n",
    "beta1 = 0.8\n",
    "log_interval = 50\n",
    "optimizer = optim.Adam([{'params': netW.parameters()},\n",
    "                        {'params': netE.parameters()},\n",
    "                        {'params': netD.parameters()}], lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([100]), 'img_input')\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 100, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 200, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 300, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 400, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 500, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 600, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 700, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 800, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 900, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 1000, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 100, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 200, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 300, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 400, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 500, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 600, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 700, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 800, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 900, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([100, 300, 1]))\n",
      "('output_feat', torch.Size([100, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 1000, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 10000]))\n",
      "('featD', torch.Size([100, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 10000, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-74f91eb5c1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-70a959b2b971>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'opt_ans_emb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_ans_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_ans_emb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;31m#             optIdx = opt_answerIdx[:,rnd,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# print(optIdx.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-59841256be86>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_feat, hidden, opt_ans_emb, vocab_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# opt_ans_emb = self.ans_emb(opt_ans.view(-1,200,9))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mans_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_ans_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         output = output.view(100,-1,self.ninp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         )\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/backends/cudnn/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             ))\n\u001b[1;32m    297\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "critD = nn.NLLLoss()\n",
    "\n",
    "if enCuda:\n",
    "    critD.cuda()\n",
    "\n",
    "# netW.cuda()\n",
    "epoch = 0\n",
    "\n",
    "trainModel(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 1, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 2, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 3, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 4, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 5, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 6, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 7, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 8, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 9, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 1, 300]))\n",
      "('his_emb', torch.Size([24, 10, 300]))\n",
      "('img input size:', torch.Size([49, 512]))\n",
      "--------------Decoder:\n",
      "('opt_ans_input', torch.Size([9, 100]))\n",
      "('featD', torch.Size([1, 300]))\n",
      "('opt_ans_emb', torch.Size([9, 100, 300]))\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "-------------Within Decoder:\n",
      "('expand feat', torch.Size([1, 300, 1]))\n",
      "('output_feat', torch.Size([1, 100, 300]))\n",
      "1/40504: mrr: 1.000000 R1: 1.000000 R5 1.000000 R10 1.000000 Mean 1.000000\n"
     ]
    }
   ],
   "source": [
    "rank_all = valModel()\n",
    "epoch = 1\n",
    "R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save_path = '~/notebooks/save'\n",
    "torch.save({'epoch': epoch,\n",
    "                    'netW': netW.state_dict(),\n",
    "                    'netD': netD.state_dict(),\n",
    "                    'netE': netE.state_dict()},\n",
    "                    '%s/epoch_%d.pth' % (save_path, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_path = ''\n",
    "# model_path = save_path\n",
    "model_path = './save/D.15-4-16/epoch_1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './save/D.15-4-16/epoch_1.pth'\n"
     ]
    }
   ],
   "source": [
    "outf = './save'\n",
    "decoder = 'D'\n",
    "\n",
    "if model_path != '':\n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    batchSize = 1\n",
    "else:\n",
    "    # create new folder.\n",
    "    t = datetime.datetime.now()\n",
    "    cur_time = '%s-%s-%s' %(t.day, t.month, t.hour)\n",
    "    save_path = os.path.join(outf, decoder + '.' + cur_time)\n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_path != '': # load the pre-trained model.\n",
    "    netW.load_state_dict(checkpoint['netW'])\n",
    "    netE.load_state_dict(checkpoint['netE'])\n",
    "    netD.load_state_dict(checkpoint['netD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([4900, 512]), 'image size')\n",
      "(torch.Size([4900, 512]), 'img_input')\n",
      "----------------Encoder:\n",
      "('ques_emb', torch.Size([16, 100, 300]))\n",
      "('his_emb', torch.Size([24, 100, 300]))\n",
      "('img input size:', torch.Size([4900, 512]))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type Variable[torch.FloatTensor] but found type Variable[torch.cuda.FloatTensor] for argument #1 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-ce1e40304472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: %d learningRate %4f train loss %4f Time: %3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_his\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-70a959b2b971>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img input size:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mfeatD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhis_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m                                                 \u001b[0mques_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m#             ans_real_emb = netW(ans_target, format='index')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-62837c85b6c5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ques_emb, his_emb, img_raw, ques_hidden, his_hidden, rnd)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimg_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mques_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mques_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mques_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mques_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mhis_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhis_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhis_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhis_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         )\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type Variable[torch.FloatTensor] but found type Variable[torch.cuda.FloatTensor] for argument #1 'mat1'"
     ]
    }
   ],
   "source": [
    "lr = 0.0004\n",
    "beta1 = 0.8\n",
    "niter = 5\n",
    "neg_batch_sample = 30 \n",
    "log_interval = 50\n",
    "save_iter = 10000000\n",
    "save_path = '~/notebooks/saved_checkpoints'\n",
    "optimizer = optim.Adam([{'params': netW.parameters()},\n",
    "                        {'params': netE.parameters()},\n",
    "                        {'params': netD.parameters()}], lr=lr, betas=(beta1, 0.999))\n",
    "enCuda = 1\n",
    "\n",
    "if enCuda:\n",
    "    torch.cuda.manual_seed(manualSeed)\n",
    "    \n",
    "critD = nn.NLLLoss()\n",
    "if enCuda:\n",
    "    critD.cuda()\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(niter):\n",
    "    t = time.time()\n",
    "    train_loss = trainModel(epoch)\n",
    "    print ('Epoch: %d learningRate %4f train loss %4f Time: %3f' % (epoch, lr, train_loss, time.time()-t))\n",
    "    train_his = {'loss': train_loss}\n",
    "\n",
    "    print('Evaluating ... ')\n",
    "    rank_all = valModel()\n",
    "    R1 = np.sum(np.array(rank_all)==1) / float(len(rank_all))\n",
    "    R5 =  np.sum(np.array(rank_all)<=5) / float(len(rank_all))\n",
    "    R10 = np.sum(np.array(rank_all)<=10) / float(len(rank_all))\n",
    "    ave = np.sum(np.array(rank_all)) / float(len(rank_all))\n",
    "    mrr = np.sum(1/(np.array(rank_all, dtype='float'))) / float(len(rank_all))\n",
    "    print ('%d/%d: mrr: %f R1: %f R5 %f R10 %f Mean %f' %(epoch, len(dataloader_val), mrr, R1, R5, R10, ave))\n",
    "    val_his = {'R1': R1, 'R5':R5, 'R10': R10, 'Mean':ave, 'mrr':mrr}\n",
    "    history.append({'epoch':epoch, 'train': train_his, 'val': val_his})\n",
    "\n",
    "#     saving the model.\n",
    "    if epoch % save_iter == 0:\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'netW': netW.state_dict(),\n",
    "                    'netD': netD.state_dict(),\n",
    "                    'netE': netE.state_dict()},\n",
    "                    '%s/epoch_%d.pth' % (save_path, epoch))\n",
    "\n",
    "        json.dump(history, open('%s/log.json' %(save_path), 'w'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
